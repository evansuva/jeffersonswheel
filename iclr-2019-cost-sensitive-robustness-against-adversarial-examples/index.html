<!doctype html>
<html class="no-js" lang="en-us">
  <head>
    <meta charset="utf-8">
    <title>ICLR 2019: Cost-Sensitive Robustness against Adversarial Examples | Jefferson&#39;s Wheel</title>
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    <link rel="stylesheet" href="//jeffersonswheel.org/css/foundation.min.css">
    <link rel="stylesheet" href="//jeffersonswheel.org/css/highlight.min.css">
    <link rel="stylesheet" href="//jeffersonswheel.org/css/font-awesome.min.css">
    <link rel="stylesheet" href="//jeffersonswheel.org/css/academicons.min.css">
    <link rel="stylesheet" href="//jeffersonswheel.org/css/fonts.css">
    <link rel="stylesheet" href="//jeffersonswheel.org/css/finite.css">
    <link rel="shortcut icon" href="/rotunda.png">  
    
  </head>
  <body>
      
    <header>
      <nav class="nav-bar">
	
	  <div class="title-bar" data-responsive-toggle="site-menu" data-hide-for="medium">	      
	    <button class="site-hamburger" type="button" data-toggle>
	      <i class="fa fa-bars fa-lg" aria-hidden="true"></i>
	    </button>
	    <div class="title-bar-title site-title">
	      <a href="//jeffersonswheel.org/">Jefferson&#39;s Wheel</a>
	    </div>
	    <div class="title-bar-right pull-right">
	      



	    </div>
	  </div>
	    
	  
	    <div class="top-bar" id="site-menu" >	      
	      <div class="top-bar-title show-for-medium site-title">
		<a href="//jeffersonswheel.org/">Jefferson&#39;s Wheel</a>
	      </div>
	      <div class="top-bar-left">
		<ul class="menu vertical medium-horizontal">
		  
		  
		</ul>
	      </div>
	      <div class="top-bar-right show-for-medium">
		



	      </div>
	    </div>
	  
	</nav>
      
    </header>
    
    <main>
      
<div class="row">
  <div class="column small-12 medium-10 medium-offset-1 end large-8 large-offset-0">
    <article class="article" itemscope itemtype="http://schema.org/Article">
      
      <h1 itemprop="name">ICLR 2019: Cost-Sensitive Robustness against Adversarial Examples</h1>
      <div class="post-metadata">
  <span class="post-date">
    <time datetime="2018-12-20 00:00:00 &#43;0000 UTC" itemprop="datePublished">20 December 2018</time>
  </span>
  
  
  
  <span class="post-tags">
    <span class="nowrap"><i class="fa fa-tags"></i>
    
    <a class="post-tag" href="//jeffersonswheel.org/tags/adversarial-machine-learning">adversarial machine learning</a>,</span> 
    
    <a class="post-tag" href="//jeffersonswheel.org/tags/xiao-zhang">Xiao Zhang</a>, 
    
    <a class="post-tag" href="//jeffersonswheel.org/tags/iclr">ICLR</a>
    
  </span>
  
  
</div>

      <div class="post-body" itemprop="articleBody">
        <p>Xiao Zhang and my paper on <a href="https://openreview.net/forum?id=BygANhA9tQ&amp;noteId=BJe7cKRWeN"><em>Cost-Sensitive Robustness against Adversarial Examples</em></a> has been accepted to ICLR 2019.</p>

<p>Several recent works have developed methods for training classifiers
that are certifiably robust against norm-bounded adversarial
perturbations. However, these methods assume that all the adversarial
transformations provide equal value for adversaries, which is seldom
the case in real-world applications. We advocate for cost-sensitive
robustness as the criteria for measuring the classifier&rsquo;s performance
for specific tasks. We encode the potential harm of different
adversarial transformations in a cost matrix, and propose a general
objective function to adapt the robust training method of Wong &amp;
Kolter (2018) to optimize for cost-sensitive robustness. Our
experiments on simple MNIST and CIFAR10 models and a variety of cost
matrices show that the proposed approach can produce models with
substantially reduced cost-sensitive robust error, while maintaining
classification accuracy.</p>

<p><center>
<img src="/images/protecteven.png" width="70%">
<div class="caption">
This shows the results of cost-sensitive robustness training to protect the odd classes. By incorporating a cost matrix in the loss function for robustness training, we can produce a model where selected transitions are more robust to adversarial transformation.
</center></p>

<p>Xiao will present the paper at ICLR in New Orleans in May 2019.</p>

      </div>

      <meta itemprop="wordCount" content="191">
      <meta itemprop="datePublished" content="2018-12-20">
      <meta itemprop="url" content="//jeffersonswheel.org/iclr-2019-cost-sensitive-robustness-against-adversarial-examples/">
    </article>

    <ul class="pagination" role="navigation" aria-label="Pagination">
      
      <li class="arrow" aria-disabled="true"><a href="//jeffersonswheel.org/a-pragmatic-introduction-to-secure-multi-party-computation/">&laquo; <em>Previous<span class="show-for-sr"> page</span></em>: A Pragmatic Introduction to Secure Multi-Party Computation</a></li>
      
      
    </ul>

    
  </div>
</div>

    </main>
    
    



    
    <div class="endofpage">
    </div>

    <script src="/js/jquery.js"></script>
    <script src="/js/what-input.js"></script>
    <script src="/js/foundation.min.js"></script>
    <script src="/js/finite.js"></script>

    
    <script src="/js/highlight.pack.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>

    
    
    
  </body>
</html>
