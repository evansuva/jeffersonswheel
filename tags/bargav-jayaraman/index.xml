<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Jefferson&#39;s Wheel</title>
    <link>//jeffersonswheel.org/tags/bargav-jayaraman/index.xml</link>
    <description>Recent content on Jefferson&#39;s Wheel</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <atom:link href="//jeffersonswheel.org/tags/bargav-jayaraman/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Research Symposium Posters</title>
      <link>//jeffersonswheel.org/research-symposium-posters/</link>
      <pubDate>Tue, 08 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>//jeffersonswheel.org/research-symposium-posters/</guid>
      <description>&lt;p&gt;Five students from our group presented posters at the department&amp;rsquo;s
&lt;a href=&#34;https://engineering.virginia.edu/cs-research-symposium-fall-2019&#34;&gt;Fall Research
Symposium&lt;/a&gt;:&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;embed src=&#34;//jeffersonswheel.org/docs/symposters2019/evaluatingdpml-poster.pdf&#34; width=&#34;95%&#34; height=&#34;300&#34; type=&#34;application/pdf&#34;&gt; &lt;br&gt;
Bargav Jayaraman, &lt;em&gt;Evaluating Differentially Private Machine Learning In Practice&lt;/em&gt;
[&lt;a href=&#34;
&lt;a href=&#34;//jeffersonswheel.org/docs/symposters2019/evaluatingdpml-poster.pdf&#34;&gt;Poster&lt;/a&gt;]&lt;br&gt;
[&lt;a href=&#34;https://www.cs.virginia.edu/~evans/pubs/usenix2019/&#34;&gt;Paper&lt;/a&gt; (USENIX Security 2019)]
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/br&gt;&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;embed src=&#34;//jeffersonswheel.org/docs/symposters2019/pretrainedvulnerable-poster.pdf&#34; width=&#34;95%&#34; height=&#34;300&#34; type=&#34;application/pdf&#34;&gt;&lt;br&gt;
Hannah Chen [&lt;a href=&#34;//jeffersonswheel.org/docs/symposters2019/pretrainedvulnerable-poster.pdf&#34;&gt;Poster&lt;/a&gt;]
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/br&gt;&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;embed src=&#34;//jeffersonswheel.org/docs/symposters2019/measuringconcentration-poster.pdf&#34; width=&#34;95%&#34; height=&#34;300&#34; type=&#34;application/pdf&#34;&gt;&lt;br&gt;
Xiao Zhang [&lt;a href=&#34;//jeffersonswheel.org/docs/symposters2019/measuringconcentration-poster.pdf&#34;&gt;Poster&lt;a&gt;]&lt;br&gt;
[&lt;a href=&#34;https://arxiv.org/abs/1905.12202&#34;&gt;Paper&lt;/a&gt; (NeurIPS 2019)]
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/br&gt;&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;embed src=&#34;//jeffersonswheel.org/docs/symposters2019/diversemodels-poster.pdf&#34; width=&#34;95%&#34; height=&#34;300&#34; type=&#34;application/pdf&#34;&gt;&lt;br&gt;
Mainudding Jonas [&lt;a href=&#34;//jeffersonswheel.org/docs/symposters2019/diversemodels-poster.pdf&#34;&gt;Poster&lt;a&gt;]
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;&lt;br&gt;&lt;/br&gt;&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;embed src=&#34;//jeffersonswheel.org/docs/symposters2019/hybridbatch-poster.pdf&#34; width=&#34;95%&#34; height=&#34;300&#34; type=&#34;application/pdf&#34;&gt;&lt;br&gt;
Fnu Suya [&lt;a href=&#34;//jeffersonswheel.org/docs/symposters2019/hybridbatch-poster.pdf&#34;&gt;Poster&lt;a&gt;]&lt;br&gt;
[&lt;a href=&#34;https://arxiv.org/abs/1908.07000&#34;&gt;Paper&lt;/a&gt; (USENIX Security 2020)]
&lt;/center&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>USENIX Security Symposium 2019</title>
      <link>//jeffersonswheel.org/usenix-security-symposium-2019/</link>
      <pubDate>Mon, 26 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>//jeffersonswheel.org/usenix-security-symposium-2019/</guid>
      <description>&lt;p&gt;Bargav Jayaraman presented our paper on &lt;a href=&#34;https://arxiv.org/abs/1902.08874&#34;&gt;&lt;em&gt;Evaluating Differentially Private Machine Learning in Practice&lt;/em&gt;&lt;/a&gt; at the &lt;a
href=&#34;https://www.usenix.org/conference/usenixsecurity19&#34;&gt;28&lt;sup&gt;th&lt;/sup&gt;
USENIX Security Symposium&lt;/em&gt;&lt;/a&gt; in Santa Clara, California.&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;script async class=&#34;speakerdeck-embed&#34; data-id=&#34;dfdd40e4ba2b46e1baee68219df82de7&#34; data-ratio=&#34;1.29456384323641&#34; src=&#34;//speakerdeck.com/assets/embed.js&#34;&gt;&lt;/script&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;&lt;center&gt;&lt;img src=&#34;//jeffersonswheel.org/images/usenix2019/bargav.jpg&#34; width=80%&#34;&gt;&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;Summary by Lea Kissner:
&lt;center&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;Hey it&amp;#39;s the results! &lt;a href=&#34;https://t.co/ru1FbkESho&#34;&gt;pic.twitter.com/ru1FbkESho&lt;/a&gt;&lt;/p&gt;&amp;mdash; Lea Kissner (@LeaKissner) &lt;a href=&#34;https://twitter.com/LeaKissner/status/1162518239177371648?ref_src=twsrc%5Etfw&#34;&gt;August 17, 2019&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;Also, great to see several UVA folks at the conference including:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://havron.dev&#34;&gt;Sam Havron&lt;/a&gt; (BSCS 2017, now a PhD student at
Cornell) presented a paper on the work he and his colleagues have
done on &lt;a href=&#34;https://havron.dev/pubs/clinicalsec.pdf&#34;&gt;computer security for victims of intimate partner violence&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;center&gt;&lt;img src=&#34;//jeffersonswheel.org/images/usenix2019/havron.jpg&#34; width=80%&#34;&gt;&lt;/center&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.guanotronic.com/~serge/&#34;&gt;Serge Egelman&lt;/a&gt; (BSCS 2004) was an author on the paper &lt;a href=&#34;https://www.usenix.org/conference/usenixsecurity19/presentation/reardon&#34;&gt;&lt;em&gt;50 Ways to Leak Your Data: An
Exploration of Apps&amp;rsquo; Circumvention of the Android Permissions
System&lt;/em&gt;&lt;/a&gt;
(which was recognized by a Distinguished Paper Award). His paper in
SOUPS on &lt;a href=&#34;https://www.usenix.org/system/files/soups2019-frik.pdf&#34;&gt;&lt;em&gt;Privacy and Security Threat Models and Mitigation
Strategies of Older
Adults&lt;/em&gt;&lt;/a&gt; was highlighted in Alex Stamos&amp;rsquo; excellent talk.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.ytian.info/&#34;&gt;Yuan Tian&lt;/a&gt; (UVA professor) presented her work on Chinese password guessability (since the student author who was planning to present was unfortunately unable to obtain a visa in time). Chinese passwords are different from those of English speakers in many interesting ways, but everyone agrees that &lt;code&gt;123456&lt;/code&gt; is a great password.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;center&gt;&lt;img src=&#34;//jeffersonswheel.org/images/usenix2019/yuantian.jpg&#34; width=80%&#34;&gt;&lt;/center&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>NeurIPS 2018: Distributed Learning without Distress</title>
      <link>//jeffersonswheel.org/neurips-2018-distributed-learning-without-distress/</link>
      <pubDate>Sat, 08 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>//jeffersonswheel.org/neurips-2018-distributed-learning-without-distress/</guid>
      <description>

&lt;p&gt;Bargav Jayaraman presented our work on privacy-preserving machine learning at the &lt;a href=&#34;https://nips.cc/Conferences/2018/&#34;&gt;32&lt;sup&gt;nd&lt;/sup&gt; &lt;em&gt;Conference on Neural Information Processing Systems&lt;/em&gt;&lt;/a&gt; (NeurIPS 2018) in Montreal.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Distributed learning&lt;/em&gt; (sometimes known as &lt;em&gt;federated learning&lt;/em&gt;)
allows a group of independent data owners to collaboratively learn a
model over their data sets without exposing their private data.  Our
approach combines &lt;em&gt;differential privacy&lt;/em&gt; with secure &lt;em&gt;multi-party
computation&lt;/em&gt; to both protect the data during training and produce a
model that provides privacy against inference attacks.&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;iframe width=&#34;560&#34; height=&#34;315&#34;
    src=&#34;https://www.youtube-nocookie.com/embed/rwyWiDyVmjE&#34;
    frameborder=&#34;0&#34; allow=&#34;accelerometer; autoplay; encrypted-media;
    gyroscope; picture-in-picture&#34; allowfullscreen&gt;&lt;/iframe&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;We explore two popular methods of differential privacy, output
perturbation and gradient perturbation, and advance the
state-of-the-art for both methods in the distributed learning
setting. In our output perturbation method, the parties combine local
models within a secure computation and then add therequired
differential privacy noise before revealing the model. In our gradient
perturbation method, the data owners collaboratively train a global
model via aniterative learning algorithm. At each iteration, the
parties aggregate their local gradients within a secure computation,
adding sufficient noise to ensure privacy before the gradient updates
are revealed. For both methods, we show that the noise can be reduced
in the multi-party setting by adding the noise inside the
securecomputation after aggregation, asymptotically improving upon the
best previous results. Experiments on real world data sets demonstrate
that our methods providesubstantial utility gains for typical privacy
requirements.&lt;/p&gt;

&lt;h2 id=&#34;code&#34;&gt;Code&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/bargavj/distributedMachineLearning&#34;&gt;&lt;em&gt;&lt;a href=&#34;https://github.com/bargavj/distributedMachineLearning&#34;&gt;https://github.com/bargavj/distributedMachineLearning&lt;/a&gt;&lt;/em&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;paper&#34;&gt;Paper&lt;/h2&gt;

&lt;p&gt;Bargav Jayaraman, Lingxiao Wang, David Evans and Quanquan Gu. &lt;a href=&#34;//www.cs.virginia.edu/evans/pubs/neurips2018/neurips2018.pdf&#34;&gt;&lt;em&gt;Distributed Learning without Distress:
Privacy-Preserving Empirical Risk Minimization&lt;/em&gt;&lt;/a&gt;. &lt;a href=&#34;https://nips.cc/Conferences/2018/&#34;&gt;32&lt;sup&gt;nd&lt;/sup&gt; Conference on Neural Information Processing Systems&lt;/a&gt; (NeurIPS). Montreal, Canada. December 2018. (&lt;a href=&#34;//www.cs.virginia.edu/evans/pubs/neurips2018/neurips2018.pdf&#34;&gt;PDF&lt;/a&gt;, 19 pages, including supplemental materials)&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>