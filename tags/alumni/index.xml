<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Jefferson&#39;s Wheel</title>
    <link>//jeffersonswheel.org/tags/alumni/index.xml</link>
    <description>Recent content on Jefferson&#39;s Wheel</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <atom:link href="//jeffersonswheel.org/tags/alumni/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>SRG Lunch</title>
      <link>//jeffersonswheel.org/srg-lunch/</link>
      <pubDate>Fri, 03 May 2019 00:00:00 +0000</pubDate>
      
      <guid>//jeffersonswheel.org/srg-lunch/</guid>
      <description>&lt;p&gt;Some photos for our lunch to celebrate the end of semester, beginning
of summer, and congratulate Weilin Xu on his PhD:&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;a href=&#34;//jeffersonswheel.org/images/ORG_DSC08199.jpg&#34;&gt;&lt;img src=&#34;//jeffersonswheel.org/images/ORG_DSC08199-2.jpg&#34;&gt;&lt;/a&gt;&lt;br&gt;
&lt;div class=&#34;caption&#34;&gt;
&lt;em&gt;Left to right&lt;/em&gt;: Jonah&amp;nbsp;Weissman, Yonghwi&amp;nbsp; Kown, Bargav&amp;nbsp;Jayaraman, Aihua&amp;nbsp;Chen, Hannah&amp;nbsp;Chen, Weilin&amp;nbsp;Xu, Riley&amp;nbsp;Spahn, David&amp;nbsp;Evans, Fnu&amp;nbsp;Suya, Yuan&amp;nbsp;Tian, Mainuddin&amp;nbsp;Jonas, Tu&amp;nbsp;Le, Faysal&amp;nbsp;Hossain, Xiao&amp;nbsp;Zhang, Jack&amp;nbsp;Verrier
&lt;/center&gt;&lt;/p&gt;

&lt;table width=&#34;95%&#34;&gt;
&lt;tr&gt;
&lt;td width=&#34;46%&#34;&gt;
&lt;a href=&#34;//jeffersonswheel.org/images/IMG_20190430_130313.jpg&#34;&gt;&lt;img src=&#34;//jeffersonswheel.org/images/IMG_20190430_130313-2.jpg&#34; height=&#34;50&#34;&gt;
&lt;/td&gt;
&lt;td width=&#34;50%&#34;&gt;
&lt;a href=&#34;//jeffersonswheel.org/images/IMG_20190430_130343.jpg&#34;&gt;&lt;img src=&#34;//jeffersonswheel.org/images/IMG_20190430_130343-2.jpg&#34; height=&#34;50&#34;&gt;
&lt;/td&gt;
&lt;/table&gt;
</description>
    </item>
    
    <item>
      <title>Congratulations Dr. Xu!</title>
      <link>//jeffersonswheel.org/congratulations-dr.-xu/</link>
      <pubDate>Mon, 15 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>//jeffersonswheel.org/congratulations-dr.-xu/</guid>
      <description>&lt;p&gt;Congratulations to Weilin Xu for successfully defending his PhD Thesis!&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;a href=&#34;//jeffersonswheel.org/images/weilin-defense-IMG_4702.jpg&#34;&gt;&lt;img src=&#34;//jeffersonswheel.org/images/weilin-defense-IMG_4702-2.jpg&#34; width=&#34;70%&#34;&gt;&lt;/a&gt;
&lt;div class=&#34;caption&#34;&gt;&lt;center&gt;
Weilin&amp;rsquo;s Committee: &lt;A href=&#34;http://faculty.virginia.edu/alemzadeh/&#34;&gt;Homa Alemzadeh&lt;/a&gt;, &lt;a href=&#34;https://www.cs.virginia.edu/yanjun/&#34;&gt;Yanjun Qi&lt;/a&gt;, &lt;a href=&#34;http://patrickmcdaniel.org/&#34;&gt;Patrick McDaniel&lt;/a&gt; (on screen)&lt;/a&gt;, &lt;a href=&#34;https://www.cs.virginia.edu/evans&#34;&gt;David Evans&lt;/a&gt;, &lt;a href=&#34;http://vicenteordonez.com/&#34;&gt;Vicente Ordóñez Román&lt;/a&gt;&lt;/center&gt;
&lt;/div&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;em&gt;Improving Robustness of Machine Learning Models using Domain Knowledge&lt;/em&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;Although machine learning techniques have achieved great success in
many areas, such as computer vision, natural language processing, and
computer security, recent studies have shown that they are not robust
under attack. A motivated adversary is often able to craft input
samples that force a machine learning model to produce incorrect
predictions, even if the target model achieves high accuracy on normal
test inputs. This raises great concern when machine learning models
are deployed for security-sensitive tasks.&lt;/p&gt;

&lt;p&gt;This dissertation aims to improve the robustness of machine learning
models by exploiting domain knowledge. While domain knowledge has
often been neglected due to the power of automatic representation
learning in the deep learning era, we find that domain knowledge goes
beyond a given dataset of a task and helps to (1) uncover weaknesses
of machine learning models, (2) detect adversarial examples and (3)
improve the robustness of machine learning models.&lt;/p&gt;

&lt;p&gt;First, we design an evolutionary algorithm-based framework,
&lt;em&gt;Genetic Evasion&lt;/em&gt;, to find evasive samples. We embed domain
knowledge into the mutation operator and the fitness function of the
framework and achieve 100% success rate in evading two
state-of-the-art PDF malware classifiers. Unlike previous methods, our
technique uses genetic programming to directly generate evasive
samples in the problem space instead of the feature space, making it a
practical attack that breaks the trust of black-box machine learning
models in a security application.&lt;/p&gt;

&lt;p&gt;Second, we design an ensemble framework, &lt;em&gt;Feature Squeezing&lt;/em&gt;, to
detect adversarial examples against deep neural network models using
simple pre-processing. We employ domain knowledge on signal processing
that natural signals are often redundant for many perception
tasks. Therefore, we can squeeze the input features to reduce
adversaries&amp;rsquo; search space while preserving the accuracy on normal
inputs.  We use various squeezers to pre-process an input example
before it is fed into a model. The difference between those
predictions is often small for normal inputs due to redundancy, while
the difference can be large for adversarial examples. We demonstrate
that &lt;em&gt;Feature Squeezing&lt;/em&gt; is empirically effective and inexpensive in
detecting adversarial examples for image classification tasks
generated by many algorithms.&lt;/p&gt;

&lt;p&gt;Third, we incorporate simple pre-processing with certifiable robust
training and formal verification to train provably-robust models. We
formally analyze the impact of pre-processing on adversarial strength
and derive novel methods to improve model robustness. Our approach
produces accurate models with verified state-of-the-art robustness and
advances the state-of-the-art of certifiable robust training methods.&lt;/p&gt;

&lt;p&gt;We demonstrate that domain knowledge helps us understand and improve
the robustness of machine learning models. Our results have motivated
several subsequent works, and we hope this dissertation will be a step
towards implementing robust models under attack.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A Plan to Eradicate Stalkerware</title>
      <link>//jeffersonswheel.org/a-plan-to-eradicate-stalkerware/</link>
      <pubDate>Wed, 03 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>//jeffersonswheel.org/a-plan-to-eradicate-stalkerware/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://www.cs.cornell.edu/~havron/&#34;&gt;Sam Havron&lt;/a&gt; (BSCS 2017) is quoted in &lt;a href=&#34;https://www.wired.com/story/eva-galperin-stalkerware-kaspersky-antivirus/&#34;&gt;an article in Wired&lt;/a&gt; on eradicating stalkerware:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;The full extent of that stalkerware crackdown will only prove out with time and testing, says Sam Havron, a Cornell researcher who worked on last year&amp;rsquo;s spyware study. Much more work remains. He notes that domestic abuse victims can also be tracked with dual-use apps often overlooked by antivirus firms, like antitheft software Cerberus. Even innocent tools like Apple&amp;rsquo;s Find My Friends and Google Maps&amp;rsquo; location-sharing features can be abused if they don&amp;rsquo;t better communicate to users that they may have been secretly configured to share their location. &amp;ldquo;This is really exciting news,&amp;rdquo; Havron says of Kaspersky&amp;rsquo;s stalkerware change. &amp;ldquo;Hopefully it will spur the rest of the industry to follow suit. But it&amp;rsquo;s just the very first thing.&amp;rdquo;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;For more details on his technical work, see the paper in Oakland 2018:
Rahul Chatterjee, Periwinkle Doerfler, Hadas Orgad, Sam Havron,
Jackeline Palmer, Diana Freed, Karen Levy, Nicola Dell, Damon McCoy,
Thomas Ristenpart. &lt;a href=&#34;https://www.ipvtechresearch.org/pubs/spyware.pdf&#34;&gt;&lt;em&gt;The Spyware Used in Intimate Partner
Violence&lt;/em&gt;&lt;/a&gt;. IEEE
Symposium on Security and Privacy, 2018.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Violations of Children’s Privacy Laws</title>
      <link>//jeffersonswheel.org/violations-of-childrens-privacy-laws/</link>
      <pubDate>Sun, 16 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>//jeffersonswheel.org/violations-of-childrens-privacy-laws/</guid>
      <description>&lt;p&gt;The New York Times has an article, &lt;a href=&#34;https://www.nytimes.com/interactive/2018/09/12/technology/kids-apps-data-privacy-google-twitter.html&#34;&gt;&lt;em&gt;How Game Apps That Captivate Kids Have Been Collecting Their Data&lt;/em&gt;&lt;/a&gt; about a lawsuit the state of New Mexico is bringing against app markets (including Google) that allow apps presented as being for children in the Play store to violate COPPA rules and mislead users into tracking children. The lawsuit stems from a study led by Serge Egleman’s group at UC Berkeley that analyzed COPPA violations in children’s apps. Serge was an undergraduate student here (back in the early 2000s) &amp;#8211; one of the things he did as a undergraduate was successfully sue a spammer.&lt;/p&gt;
&lt;p&gt;The original paper about the study: &lt;a href=&#34;https://blues.cs.berkeley.edu/wp-content/uploads/2018/04/popets-2018-0021.pdf&#34;&gt;“Won’t Somebody Think of the Children?” Examining COPPA Compliance at Scale&lt;/a&gt;, Irwin Reyes, Primal Wijesekera, Joel Reardon, Amit Elazari Bar On, Abbas Razaghpanah, Narseo Vallina-Rodriguez, and Serge Egelman. Proceedings on Privacy Enhancing Technologies (PETS) 2018.&lt;/p&gt;
&lt;p&gt;&lt;center&gt;&lt;br /&gt;
&lt;img src=&#34;https://static01.nyt.com/images/2018/09/13/autossell/13Kidapps2/13Kidapps2-superJumbo.jpg&#34; width=&#34;80%&#34;&gt;&lt;br /&gt;
&lt;div class=&#34;caption&#34;&gt;
Serge Egelman, a researcher with the International Computer Science Institute and the University of California, Berkeley, helped lead the study of nearly 6,000 children’s Android apps&lt;br /&gt;
&lt;/div&gt;
&lt;/center&gt;&lt;/p&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Wahoos at Oakland</title>
      <link>//jeffersonswheel.org/wahoos-at-oakland/</link>
      <pubDate>Tue, 29 May 2018 00:00:00 +0000</pubDate>
      
      <guid>//jeffersonswheel.org/wahoos-at-oakland/</guid>
      <description>

&lt;h2 id=&#34;uva-group-dinner-at-ieee-security-and-privacy-2018&#34;&gt;UVA Group Dinner at IEEE Security and Privacy 2018&lt;/h2&gt;

&lt;p&gt;Including our newest faculty member, &lt;a href=&#34;https://www.cs.purdue.edu/homes/kwon58/#summary&#34;&gt;Yongwhi Kwon&lt;/a&gt;, joining UVA in Fall 2018!&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;center&gt;&lt;br /&gt;
&lt;a href=&#34;//jeffersonswheel.org/images/srg2018/ORG_DSC07202.jpg&#34;&gt;&lt;img src=&#34;//jeffersonswheel.org/images/srg2018/ORG_DSC07202.jpg&#34; width=&#34;680&#34;&gt;&lt;/a&gt;&lt;br /&gt;
&lt;small&gt;Yuan Tian, Fnu Suya, Mainuddin Jonas, Yongwhi Kwon, David Evans, Weihang Wang, Aihua&amp;nbsp;Chen,&amp;nbsp;Weilin&amp;nbsp;Xu&lt;/small&gt;&lt;br /&gt;
&lt;/center&gt;
&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;

&lt;h2 id=&#34;poster-session&#34;&gt;Poster Session&lt;/h2&gt;

&lt;table width=&#34;100%&#34;&gt;
&lt;tr valign=&#34;top&#34;&gt;
&lt;td width=&#34;50%&#34; align=&#34;center&#34;&gt;
&lt;a href=&#34;//jeffersonswheel.org/images/srg2018/IMG_20180521_193906.jpg&#34;&gt;&lt;img src=&#34;//jeffersonswheel.org/images/srg2018/IMG_20180521_193906-3.jpg&#34; height=&#34;360&#34;&gt;&lt;/a&gt;&lt;br /&gt;
Fnu Suya (with Yuan Tian and David Evans), &lt;em&gt;Adversaries Don’t Care About Averages: Batch Attacks on Black-Box Classifiers&lt;/em&gt; &lt;a href=&#34;https://www.ieee-security.org/TC/SP2018/poster-abstracts/oakland2018-paper37-poster-abstract.pdf&#34;&gt;[PDF]&lt;/a&gt;
&lt;/td&gt;
&lt;td width=&#34;50%&#34; align=&#34;center&#34;&gt;
&lt;a href=&#34;//jeffersonswheel.org/images/srg2018/IMG_20180521_193914.jpg&#34;&gt;&lt;img src=&#34;//jeffersonswheel.org/images/srg2018/IMG_20180521_193914-2.jpg&#34; height=&#34;360&#34;&gt;&lt;/a&gt;&lt;br /&gt;
Mainuddin Jonas (with David Evans), &lt;em&gt;Enhancing Adversarial Example Defenses Using Internal Layers&lt;/em&gt; &lt;a href=&#34;https://www.ieee-security.org/TC/SP2018/poster-abstracts/oakland2018-paper29-poster-abstract.pdf&#34;&gt;[PDF]&lt;/a&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr valign=&#34;top&#34;&gt;
&lt;td width=&#34;50%&#34; align=&#34;center&#34;&gt;
&lt;a href=&#34;//jeffersonswheel.org/images/srg2018/IMG_20180522_153017.jpg&#34;&gt;&lt;img src=&#34;//jeffersonswheel.org/images/srg2018/IMG_20180522_153017-2.jpg&#34; height=&#34;300&#34;&gt;&lt;/a&gt;
&lt;/td&gt;
&lt;td width=&#34;50%&#34; align=&#34;center&#34;&gt;
&lt;a href=&#34;//jeffersonswheel.org/images/srg2018/IMG_20180522_153109.jpg&#34;&gt;&lt;img src=&#34;//jeffersonswheel.org/images/srg2018/IMG_20180522_153109-2.jpg&#34; height=&#34;300&#34;&gt;&lt;/a&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
</description>
    </item>
    
  </channel>
</rss>