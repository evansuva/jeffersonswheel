<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Jianfeng Chi on Jefferson&#39;s Wheel</title>
    <link>//jeffersonswheel.org/tags/jianfeng-chi/</link>
    <description>Recent content in Jianfeng Chi on Jefferson&#39;s Wheel</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 14 Dec 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="//jeffersonswheel.org/tags/jianfeng-chi/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>USENIX Security 2020: Hybrid Batch Attacks</title>
      <link>//jeffersonswheel.org/usenix-security-2020-hybrid-batch-attacks/</link>
      <pubDate>Sat, 14 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>//jeffersonswheel.org/usenix-security-2020-hybrid-batch-attacks/</guid>
      <description>Finding Black-box Adversarial Examples with Limited Queries Black-box attacks generate adversarial examples (AEs) against deep neural networks with only API access to the victim model.
Existing black-box attacks can be grouped into two main categories:
  Transfer Attacks use white-box attacks on local models to find candidate adversarial examples that transfer to the target model.
  Optimization Attacks use queries to the target model and apply optimization techniques to search for adversarial examples.</description>
    </item>
    
  </channel>
</rss>