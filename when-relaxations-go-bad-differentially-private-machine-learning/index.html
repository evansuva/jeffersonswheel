<!doctype html>
<html class="no-js" lang="en-us">
  <head>
    <meta charset="utf-8">
    <title>When Relaxations Go Bad: &#34;Differentially-Private&#34; Machine Learning | Jefferson&#39;s Wheel</title>
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    <link rel="stylesheet" href="//jeffersonswheel.org/css/foundation.min.css">
    <link rel="stylesheet" href="//jeffersonswheel.org/css/highlight.min.css">
    <link rel="stylesheet" href="//jeffersonswheel.org/css/font-awesome.min.css">
    <link rel="stylesheet" href="//jeffersonswheel.org/css/academicons.min.css">
    <link rel="stylesheet" href="//jeffersonswheel.org/css/fonts.css">
    <link rel="stylesheet" href="//jeffersonswheel.org/css/finite.css">
    <link rel="shortcut icon" href="/rotunda.png">  
    
  </head>
  <body>
      
    <header>
      <nav class="nav-bar">
	
	  <div class="title-bar" data-responsive-toggle="site-menu" data-hide-for="medium">	      
	    <button class="site-hamburger" type="button" data-toggle>
	      <i class="fa fa-bars fa-lg" aria-hidden="true"></i>
	    </button>
	    <div class="title-bar-title site-title">
	      <a href="//jeffersonswheel.org/">Jefferson&#39;s Wheel</a>
	    </div>
	    <div class="title-bar-right pull-right">
	      



	    </div>
	  </div>
	    
	  
	    <div class="top-bar" id="site-menu" >	      
	      <div class="top-bar-title show-for-medium site-title">
		<a href="//jeffersonswheel.org/">Jefferson&#39;s Wheel</a>
	      </div>
	      <div class="top-bar-left">
		<ul class="menu vertical medium-horizontal">
		  
		  
		</ul>
	      </div>
	      <div class="top-bar-right show-for-medium">
		



	      </div>
	    </div>
	  
	</nav>
      
    </header>
    
    <main>
      
<div class="row">
  <div class="column small-12 medium-10 medium-offset-1 end large-8 large-offset-0">
    <article class="article" itemscope itemtype="http://schema.org/Article">
      
      <h1 itemprop="name">When Relaxations Go Bad: &#34;Differentially-Private&#34; Machine Learning</h1>
      <div class="post-metadata">
  <span class="post-date">
    <time datetime="2019-03-09 00:00:00 &#43;0000 UTC" itemprop="datePublished">9 March 2019</time>
  </span>
  
  
  
  <span class="post-tags">
    <span class="nowrap"><i class="fa fa-tags"></i>
    
    <a class="post-tag" href="//jeffersonswheel.org/tags/privacy">privacy</a>,</span> 
    
    <a class="post-tag" href="//jeffersonswheel.org/tags/privacy-preserving-machine-learning">privacy-preserving machine learning</a>, 
    
    <a class="post-tag" href="//jeffersonswheel.org/tags/differential-privacy">differential privacy</a>, 
    
    <a class="post-tag" href="//jeffersonswheel.org/tags/bargav-jayaraman">Bargav Jayaraman</a>
    
  </span>
  
  
</div>

      <div class="post-body" itemprop="articleBody">
        <p>We have posted a paper by Bargav Jayaraman and myself on <a href="https://arxiv.org/abs/1902.08874"><em>When Relaxations Go Bad: &ldquo;Differentially-Private&rdquo; Machine Learning</em></a> (code available at <a href="https://github.com/bargavj/EvaluatingDPML">https://github.com/bargavj/EvaluatingDPML</a>).</p>

<p>Differential privacy is becoming a standard notion for performing
privacy-preserving machine learning over sensitive data. It provides
formal guarantees, in terms of the privacy budget, &epsilon;, on how
much information about individual training records is leaked by the
model.</p>

<p>While the privacy budget is directly correlated to the privacy
leakage, the calibration of the privacy budget is not well
understood. As a result, many existing works on privacy-preserving
machine learning select large values of Ïµ in order to get acceptable
utility of the model, with little understanding of the concrete impact
of such choices on meaningful privacy. Moreover, in scenarios where
iterative learning procedures are used which require privacy
guarantees for each iteration, relaxed definitions of differential
privacy are often used which further tradeoff privacy for better
utility.</p>

<p>In this paper, we evaluate the impacts of these choices on privacy in
experiments with logistic regression and neural network models. We
quantify the privacy leakage in terms of advantage of the adversary
performing inference attacks and by analyzing the number of members at
risk for exposure.</p>

<p><div class="myrow">
   <div class="mycolumn" align="center">
<a href="/images/cifar_nn_grad_add.pdf"><img src="/images/cifar_nn_grad_acc.png" width="92%"></a><br>
Accuracy Loss as Privacy Decreases<br>
(CIFAR-100, neural network model)
   </div>
   <div class="mycolumn" align="center">
<a href="/images/Cifar_nn_grad_mem.pdf"><img src="/images/Cifar_nn_grad_mem.png" width="98%"></a><br>
Privacy Leakage<br>
(Yeom et al.&rsquo;s Membership Inference Attack)
   </div>
   </div></p>

<p>Our main findings are that current mechanisms for differential privacy
for machine learning rarely offer acceptable utility-privacy
tradeoffs: settings that provide limited accuracy loss provide little
effective privacy, and settings that provide strong privacy result in
useless models.</p>

<p>Bargav Jayaraman talked about this work at the <em>DC-Area Anonymity, Privacy, and Security Seminar</em>(<a href="https://dcaps.info/2019-2-25.html">https://dcaps.info/2019-2-25.html</a>) (25 February 2019) at the University of Maryland:</p>

<script async class="speakerdeck-embed" data-id="294ac688ec6d415a9bef17a91e031459" data-ratio="1.77777777777778" src="//speakerdeck.com/assets/embed.js"></script>

<p>Paper: <a href="https://arxiv.org/abs/1902.08874"><em>When Relaxations Go Bad: &ldquo;Differentially-Private&rdquo; Machine Learning</em></a><br />
Code: <a href="https://github.com/bargavj/EvaluatingDPML">https://github.com/bargavj/EvaluatingDPML</a>)</p>

      </div>

      <meta itemprop="wordCount" content="284">
      <meta itemprop="datePublished" content="2019-03-09">
      <meta itemprop="url" content="//jeffersonswheel.org/when-relaxations-go-bad-differentially-private-machine-learning/">
    </article>

    <ul class="pagination" role="navigation" aria-label="Pagination">
      
      <li class="arrow" aria-disabled="true"><a href="//jeffersonswheel.org/deep-fools/">&laquo; <em>Previous<span class="show-for-sr"> page</span></em>: Deep Fools</a></li>
      
      
    </ul>

  </div>
</div>

    </main>
    
    
<footer class="whatisthis">
  <hr />
  <div class="row">
    <div class="column small-6 medium-2">
      <figure class="full-figure">
	<a href="//jeffersonswheel.org"><img src="/images/jwlogo-small.png" width="160" height="100" alt="Jefferson's Wheel"></a>
	
      </figure>
    </div>
    <div class="column small-12 medium-4">
      <a href="//jeffersonswheel.org"><b>Security Research Group</b></a><br>
      <a href="//www.cs.virginia.edu/">University of Virginia</a><br>
      <a href="mailto:evans@virginia.edu"><em>evans@virginia.edu</em></a>
    </div>
    <div class="column small-14 medium-5">
      <font size="-1">
      Subscribe to
	the <a href="/index.xml"><i class="fa fa-rss-square"></i>&nbsp;RSS feed</a>.
      <a id="searchsite">
	<form method="get" action="https://duckduckgo.com/">
	  <label for="search-field" class="show-for-sr">Search with DuckDuckGo</label>
	  <input type="search" name="q" maxlength="255" placeholder="Search with DuckDuckGo" id="search-field">
	  <input type="hidden" name="sites" value="//jeffersonswheel.org/"/>
	  <input type="hidden" name="k7" value="#faf8f8"/>
	  <input type="hidden" name="kj" value="#b33"/>
	  <input type="hidden" name="ky" value="#fafafa"/>
	  <input type="hidden" name="kx" value="b"/>
	  <input type="hidden" name="ko" value="-1"/>
	  <input type="hidden" name="k1" value="-1"/>
	  <input type="submit" value="DuckDuckGo Search" style="visibility: hidden;" />
	</form>
      </a>
</font>
    </div>
  </div>
</footer>


    
    <div class="endofpage">
    </div>

    <script src="/js/jquery.js"></script>
    <script src="/js/what-input.js"></script>
    <script src="/js/foundation.min.js"></script>
    <script src="/js/finite.js"></script>

    
    <script src="/js/highlight.pack.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>

    
    
    
  </body>
</html>
