<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Jefferson&#39;s Wheel</title>
    <link>//jeffersonswheel.org/tags/weilin-xu/index.xml</link>
    <description>Recent content on Jefferson&#39;s Wheel</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <atom:link href="//jeffersonswheel.org/tags/weilin-xu/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Graduation 2019</title>
      <link>//jeffersonswheel.org/graduation-2019/</link>
      <pubDate>Wed, 05 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>//jeffersonswheel.org/graduation-2019/</guid>
      <description>&lt;p&gt;&lt;center&gt;
&lt;a href=&#34;//jeffersonswheel.org/images/graduation2019/IMG_0171.jpg&#34;&gt;&lt;img src=&#34;//jeffersonswheel.org/images/graduation2019/IMG_0171-2.jpg&#34; height=120&gt;&lt;/a&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;table align=&#34;center&#34; width=&#34;60%&#34;&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;a href=&#34;//jeffersonswheel.org/images/graduation2019/IMG_0116.jpg&#34;&gt;&lt;img src=&#34;//jeffersonswheel.org/images/graduation2019/IMG_0116-2.jpg&#34; height=&#34;100&#34;&gt;&lt;/a&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;a href=&#34;//jeffersonswheel.org/images/graduation2019/IMG-0175.jpg&#34;&gt;&lt;img src=&#34;//jeffersonswheel.org/images/graduation2019/IMG_0175-2.jpg&#34; height=&#34;100&#34;&gt;&lt;/a&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;

&lt;p&gt;&lt;center&gt;
&lt;a href=&#34;//jeffersonswheel.org/images/graduation2019/IMG_0193.jpg&#34;&gt;&lt;img src=&#34;//jeffersonswheel.org/images/graduation2019/IMG_0193-2.jpg&#34; height=120&gt;&lt;/a&gt;
&lt;/center&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>SRG Lunch</title>
      <link>//jeffersonswheel.org/srg-lunch/</link>
      <pubDate>Fri, 03 May 2019 00:00:00 +0000</pubDate>
      
      <guid>//jeffersonswheel.org/srg-lunch/</guid>
      <description>&lt;p&gt;Some photos for our lunch to celebrate the end of semester, beginning
of summer, and congratulate Weilin Xu on his PhD:&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;a href=&#34;//jeffersonswheel.org/images/ORG_DSC08199.jpg&#34;&gt;&lt;img src=&#34;//jeffersonswheel.org/images/ORG_DSC08199-2.jpg&#34;&gt;&lt;/a&gt;&lt;br&gt;
&lt;div class=&#34;caption&#34;&gt;
&lt;em&gt;Left to right&lt;/em&gt;: Jonah&amp;nbsp;Weissman, Yonghwi&amp;nbsp; Kown, Bargav&amp;nbsp;Jayaraman, Aihua&amp;nbsp;Chen, Hannah&amp;nbsp;Chen, Weilin&amp;nbsp;Xu, Riley&amp;nbsp;Spahn, David&amp;nbsp;Evans, Fnu&amp;nbsp;Suya, Yuan&amp;nbsp;Tian, Mainuddin&amp;nbsp;Jonas, Tu&amp;nbsp;Le, Faysal&amp;nbsp;Hossain, Xiao&amp;nbsp;Zhang, Jack&amp;nbsp;Verrier
&lt;/center&gt;&lt;/p&gt;

&lt;table width=&#34;95%&#34;&gt;
&lt;tr&gt;
&lt;td width=&#34;46%&#34;&gt;
&lt;a href=&#34;//jeffersonswheel.org/images/IMG_20190430_130313.jpg&#34;&gt;&lt;img src=&#34;//jeffersonswheel.org/images/IMG_20190430_130313-2.jpg&#34; height=&#34;50&#34;&gt;
&lt;/td&gt;
&lt;td width=&#34;50%&#34;&gt;
&lt;a href=&#34;//jeffersonswheel.org/images/IMG_20190430_130343.jpg&#34;&gt;&lt;img src=&#34;//jeffersonswheel.org/images/IMG_20190430_130343-2.jpg&#34; height=&#34;50&#34;&gt;
&lt;/td&gt;
&lt;/table&gt;
</description>
    </item>
    
    <item>
      <title>Congratulations Dr. Xu!</title>
      <link>//jeffersonswheel.org/congratulations-dr.-xu/</link>
      <pubDate>Mon, 15 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>//jeffersonswheel.org/congratulations-dr.-xu/</guid>
      <description>&lt;p&gt;Congratulations to Weilin Xu for successfully defending his PhD Thesis!&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;a href=&#34;//jeffersonswheel.org/images/weilin-defense-IMG_4702.jpg&#34;&gt;&lt;img src=&#34;//jeffersonswheel.org/images/weilin-defense-IMG_4702-2.jpg&#34; width=&#34;70%&#34;&gt;&lt;/a&gt;
&lt;div class=&#34;caption&#34;&gt;&lt;center&gt;
Weilin&amp;rsquo;s Committee: &lt;A href=&#34;http://faculty.virginia.edu/alemzadeh/&#34;&gt;Homa Alemzadeh&lt;/a&gt;, &lt;a href=&#34;https://www.cs.virginia.edu/yanjun/&#34;&gt;Yanjun Qi&lt;/a&gt;, &lt;a href=&#34;http://patrickmcdaniel.org/&#34;&gt;Patrick McDaniel&lt;/a&gt; (on screen)&lt;/a&gt;, &lt;a href=&#34;https://www.cs.virginia.edu/evans&#34;&gt;David Evans&lt;/a&gt;, &lt;a href=&#34;http://vicenteordonez.com/&#34;&gt;Vicente Ordóñez Román&lt;/a&gt;&lt;/center&gt;
&lt;/div&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;&lt;center&gt;
&lt;em&gt;Improving Robustness of Machine Learning Models using Domain Knowledge&lt;/em&gt;
&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;Although machine learning techniques have achieved great success in
many areas, such as computer vision, natural language processing, and
computer security, recent studies have shown that they are not robust
under attack. A motivated adversary is often able to craft input
samples that force a machine learning model to produce incorrect
predictions, even if the target model achieves high accuracy on normal
test inputs. This raises great concern when machine learning models
are deployed for security-sensitive tasks.&lt;/p&gt;

&lt;p&gt;This dissertation aims to improve the robustness of machine learning
models by exploiting domain knowledge. While domain knowledge has
often been neglected due to the power of automatic representation
learning in the deep learning era, we find that domain knowledge goes
beyond a given dataset of a task and helps to (1) uncover weaknesses
of machine learning models, (2) detect adversarial examples and (3)
improve the robustness of machine learning models.&lt;/p&gt;

&lt;p&gt;First, we design an evolutionary algorithm-based framework,
&lt;em&gt;Genetic Evasion&lt;/em&gt;, to find evasive samples. We embed domain
knowledge into the mutation operator and the fitness function of the
framework and achieve 100% success rate in evading two
state-of-the-art PDF malware classifiers. Unlike previous methods, our
technique uses genetic programming to directly generate evasive
samples in the problem space instead of the feature space, making it a
practical attack that breaks the trust of black-box machine learning
models in a security application.&lt;/p&gt;

&lt;p&gt;Second, we design an ensemble framework, &lt;em&gt;Feature Squeezing&lt;/em&gt;, to
detect adversarial examples against deep neural network models using
simple pre-processing. We employ domain knowledge on signal processing
that natural signals are often redundant for many perception
tasks. Therefore, we can squeeze the input features to reduce
adversaries&amp;rsquo; search space while preserving the accuracy on normal
inputs.  We use various squeezers to pre-process an input example
before it is fed into a model. The difference between those
predictions is often small for normal inputs due to redundancy, while
the difference can be large for adversarial examples. We demonstrate
that &lt;em&gt;Feature Squeezing&lt;/em&gt; is empirically effective and inexpensive in
detecting adversarial examples for image classification tasks
generated by many algorithms.&lt;/p&gt;

&lt;p&gt;Third, we incorporate simple pre-processing with certifiable robust
training and formal verification to train provably-robust models. We
formally analyze the impact of pre-processing on adversarial strength
and derive novel methods to improve model robustness. Our approach
produces accurate models with verified state-of-the-art robustness and
advances the state-of-the-art of certifiable robust training methods.&lt;/p&gt;

&lt;p&gt;We demonstrate that domain knowledge helps us understand and improve
the robustness of machine learning models. Our results have motivated
several subsequent works, and we hope this dissertation will be a step
towards implementing robust models under attack.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Wahoos at Oakland</title>
      <link>//jeffersonswheel.org/wahoos-at-oakland/</link>
      <pubDate>Tue, 29 May 2018 00:00:00 +0000</pubDate>
      
      <guid>//jeffersonswheel.org/wahoos-at-oakland/</guid>
      <description>

&lt;h2 id=&#34;uva-group-dinner-at-ieee-security-and-privacy-2018&#34;&gt;UVA Group Dinner at IEEE Security and Privacy 2018&lt;/h2&gt;

&lt;p&gt;Including our newest faculty member, &lt;a href=&#34;https://www.cs.purdue.edu/homes/kwon58/#summary&#34;&gt;Yongwhi Kwon&lt;/a&gt;, joining UVA in Fall 2018!&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;center&gt;&lt;br /&gt;
&lt;a href=&#34;//jeffersonswheel.org/images/srg2018/ORG_DSC07202.jpg&#34;&gt;&lt;img src=&#34;//jeffersonswheel.org/images/srg2018/ORG_DSC07202.jpg&#34; width=&#34;680&#34;&gt;&lt;/a&gt;&lt;br /&gt;
&lt;small&gt;Yuan Tian, Fnu Suya, Mainuddin Jonas, Yongwhi Kwon, David Evans, Weihang Wang, Aihua&amp;nbsp;Chen,&amp;nbsp;Weilin&amp;nbsp;Xu&lt;/small&gt;&lt;br /&gt;
&lt;/center&gt;
&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;

&lt;h2 id=&#34;poster-session&#34;&gt;Poster Session&lt;/h2&gt;

&lt;table width=&#34;100%&#34;&gt;
&lt;tr valign=&#34;top&#34;&gt;
&lt;td width=&#34;50%&#34; align=&#34;center&#34;&gt;
&lt;a href=&#34;//jeffersonswheel.org/images/srg2018/IMG_20180521_193906.jpg&#34;&gt;&lt;img src=&#34;//jeffersonswheel.org/images/srg2018/IMG_20180521_193906-3.jpg&#34; height=&#34;360&#34;&gt;&lt;/a&gt;&lt;br /&gt;
Fnu Suya (with Yuan Tian and David Evans), &lt;em&gt;Adversaries Don’t Care About Averages: Batch Attacks on Black-Box Classifiers&lt;/em&gt; &lt;a href=&#34;https://www.ieee-security.org/TC/SP2018/poster-abstracts/oakland2018-paper37-poster-abstract.pdf&#34;&gt;[PDF]&lt;/a&gt;
&lt;/td&gt;
&lt;td width=&#34;50%&#34; align=&#34;center&#34;&gt;
&lt;a href=&#34;//jeffersonswheel.org/images/srg2018/IMG_20180521_193914.jpg&#34;&gt;&lt;img src=&#34;//jeffersonswheel.org/images/srg2018/IMG_20180521_193914-2.jpg&#34; height=&#34;360&#34;&gt;&lt;/a&gt;&lt;br /&gt;
Mainuddin Jonas (with David Evans), &lt;em&gt;Enhancing Adversarial Example Defenses Using Internal Layers&lt;/em&gt; &lt;a href=&#34;https://www.ieee-security.org/TC/SP2018/poster-abstracts/oakland2018-paper29-poster-abstract.pdf&#34;&gt;[PDF]&lt;/a&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr valign=&#34;top&#34;&gt;
&lt;td width=&#34;50%&#34; align=&#34;center&#34;&gt;
&lt;a href=&#34;//jeffersonswheel.org/images/srg2018/IMG_20180522_153017.jpg&#34;&gt;&lt;img src=&#34;//jeffersonswheel.org/images/srg2018/IMG_20180522_153017-2.jpg&#34; height=&#34;300&#34;&gt;&lt;/a&gt;
&lt;/td&gt;
&lt;td width=&#34;50%&#34; align=&#34;center&#34;&gt;
&lt;a href=&#34;//jeffersonswheel.org/images/srg2018/IMG_20180522_153109.jpg&#34;&gt;&lt;img src=&#34;//jeffersonswheel.org/images/srg2018/IMG_20180522_153109-2.jpg&#34; height=&#34;300&#34;&gt;&lt;/a&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
</description>
    </item>
    
    <item>
      <title>Feature Squeezing at NDSS</title>
      <link>//jeffersonswheel.org/feature-squeezing-at-ndss/</link>
      <pubDate>Sun, 25 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>//jeffersonswheel.org/feature-squeezing-at-ndss/</guid>
      <description>&lt;p&gt;Weilin Xu presented &lt;em&gt;Feature Squeezing: Detecting Adversarial Examples in Deep Neural Networks&lt;/em&gt; at the &lt;a href=&#34;http://www.ndss-symposium.org/ndss2018/&#34;&gt;Network and Distributed System Security Symposium 2018&lt;/a&gt;. San Diego, CA. 21 February 2018.&lt;br /&gt;
&lt;center&gt;&lt;br /&gt;
&lt;script async class=&#34;speakerdeck-embed&#34; data-id=&#34;cdfcf454436240e4ab1a6c4d594e5c7a&#34; data-ratio=&#34;1.77777777777778&#34; src=&#34;http://speakerdeck.com/assets/embed.js&#34;&gt;&lt;/script&gt;&lt;br /&gt;
&lt;/center&gt;&lt;/p&gt;
&lt;p&gt;
Paper: Weilin Xu, David Evans, Yanjun Qi. &lt;em&gt;Feature Squeezing: Detecting Adversarial Examples in Deep Neural Networks&lt;/em&gt;. NDSS 2018. [&lt;a href=&#34;https://evademl.org/docs/featuresqueezing.pdf&#34;&gt;PDF&lt;/a&gt;]&lt;/p&gt;&lt;/p&gt;

&lt;p&gt;Project Site: &lt;a href=&#34;https://evademl.org/squeezing&#34;&gt;EvadeML.org&lt;/a&gt;&lt;/p&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>