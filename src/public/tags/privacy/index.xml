<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Jefferson&#39;s Wheel</title>
    <link>//jeffersonswheel.org/tags/privacy/index.xml</link>
    <description>Recent content on Jefferson&#39;s Wheel</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <atom:link href="//jeffersonswheel.org/tags/privacy/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>When Relaxations Go Bad: &#34;Differentially-Private&#34; Machine Learning</title>
      <link>//jeffersonswheel.org/when-relaxations-go-bad-differentially-private-machine-learning/</link>
      <pubDate>Sat, 09 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>//jeffersonswheel.org/when-relaxations-go-bad-differentially-private-machine-learning/</guid>
      <description>&lt;p&gt;We have posted a paper by Bargav Jayaraman and myself on &lt;a href=&#34;https://arxiv.org/abs/1902.08874&#34;&gt;&lt;em&gt;When Relaxations Go Bad: &amp;ldquo;Differentially-Private&amp;rdquo; Machine Learning&lt;/em&gt;&lt;/a&gt; (code available at &lt;a href=&#34;https://github.com/bargavj/EvaluatingDPML&#34;&gt;https://github.com/bargavj/EvaluatingDPML&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;Differential privacy is becoming a standard notion for performing
privacy-preserving machine learning over sensitive data. It provides
formal guarantees, in terms of the privacy budget, &amp;epsilon;, on how
much information about individual training records is leaked by the
model.&lt;/p&gt;

&lt;p&gt;While the privacy budget is directly correlated to the privacy
leakage, the calibration of the privacy budget is not well
understood. As a result, many existing works on privacy-preserving
machine learning select large values of ϵ in order to get acceptable
utility of the model, with little understanding of the concrete impact
of such choices on meaningful privacy. Moreover, in scenarios where
iterative learning procedures are used which require privacy
guarantees for each iteration, relaxed definitions of differential
privacy are often used which further tradeoff privacy for better
utility.&lt;/p&gt;

&lt;p&gt;We evaluated the impacts of these choices on privacy in experiments
with logistic regression and neural network models, quantifying the
privacy leakage in terms of advantage of the adversary performing
inference attacks and by analyzing the number of members at risk for
exposure.&lt;/p&gt;

&lt;p&gt;&lt;div class=&#34;myrow&#34;&gt;
   &lt;div class=&#34;mycolumn&#34; align=&#34;center&#34;&gt;
&lt;a href=&#34;//jeffersonswheel.org/images/cifar_nn_grad_add.pdf&#34;&gt;&lt;img src=&#34;//jeffersonswheel.org/images/cifar_nn_grad_acc.png&#34; width=&#34;92%&#34;&gt;&lt;/a&gt;&lt;br&gt;
Accuracy Loss as Privacy Decreases&lt;br&gt;
(CIFAR-100, neural network model)
   &lt;/div&gt;
   &lt;div class=&#34;mycolumn&#34; align=&#34;center&#34;&gt;
&lt;a href=&#34;//jeffersonswheel.org/images/Cifar_nn_grad_mem.pdf&#34;&gt;&lt;img src=&#34;//jeffersonswheel.org/images/Cifar_nn_grad_mem.png&#34; width=&#34;98%&#34;&gt;&lt;/a&gt;&lt;br&gt;
Privacy Leakage&lt;br&gt;
(Yeom et al.&amp;rsquo;s Membership Inference Attack)
   &lt;/div&gt;
   &lt;/div&gt;&lt;/p&gt;

&lt;p&gt;Our main findings are that current mechanisms for differential privacy
for machine learning rarely offer acceptable utility-privacy
tradeoffs: settings that provide limited accuracy loss provide little
effective privacy, and settings that provide strong privacy result in
useless models.&lt;/p&gt;

&lt;p&gt;The table below shows the number of individuals, out of 10,000 members
in the training set, exposed by a membership inference attack, given
tolerance for false positives of 1% or 5% (and assuming a priori
prevalence of 50% members). The key observations is that all the
relaxtions provide lower utility (more accuracy loss) than na&amp;iuml;ve
composition for comparable privacy leakage, as measured by the number
of actual members exposed in a test dataset.  Further, none of the
methods provide both acceptable utility and meaningful privacy &amp;mdash;
it a high level, either nothing is learned from the training data, or
some sensitive data is exposed. (See &lt;a href=&#34;https://arxiv.org/abs/1902.08874&#34;&gt;the
paper&lt;/a&gt; for more details and
results.)&lt;/p&gt;

&lt;p&gt;&lt;style type=&#34;text/css&#34;&gt;
.tg  {border-collapse:collapse;border-spacing:0;}
.tg td{font-family:WorkSans, sans;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:black;text-align:center;}
.tg th{font-family:Merriweather,serif;font-size:14px;font-weight:bold;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:black;text-align:center;}
.tg .tg-0lax{text-align:center;vertical-align:top}
&lt;/style&gt;
&lt;table class=&#34;tg&#34;&gt;
  &lt;tr&gt;
    &lt;th class=&#34;tg-0lax&#34;&gt;﻿&lt;/th&gt;
    &lt;th class=&#34;tg-0lax&#34; colspan=&#34;3&#34; text-align=&#34;center&#34;&gt;Na&amp;iuml;ve Composition&lt;/th&gt;
    &lt;th class=&#34;tg-0lax&#34; colspan=&#34;3&#34;&gt;Advanced Composition&lt;/th&gt;
    &lt;th class=&#34;tg-0lax&#34; colspan=&#34;3&#34;&gt;Zero Concentrated&lt;/th&gt;
    &lt;th class=&#34;tg-0lax&#34; colspan=&#34;3&#34;&gt;R&amp;eacute;nyi&lt;/th&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;th class=&#34;tg-0lax&#34;&gt;Epsilon&lt;/th&gt;
    &lt;th class=&#34;tg-0lax&#34;&gt;Loss&lt;/th&gt;
    &lt;th class=&#34;tg-0lax&#34;&gt;1%&lt;/th&gt;
    &lt;th class=&#34;tg-0lax&#34;&gt;5%&lt;/th&gt;
    &lt;th class=&#34;tg-0lax&#34;&gt;Loss&lt;/th&gt;
    &lt;th class=&#34;tg-0lax&#34;&gt;1%&lt;/th&gt;
    &lt;th class=&#34;tg-0lax&#34;&gt;5%&lt;/th&gt;
    &lt;th class=&#34;tg-0lax&#34;&gt;Loss&lt;/th&gt;
    &lt;th class=&#34;tg-0lax&#34;&gt;1%&lt;/th&gt;
    &lt;th class=&#34;tg-0lax&#34;&gt;5%&lt;/th&gt;
    &lt;th class=&#34;tg-0lax&#34;&gt;Loss&lt;/th&gt;
    &lt;th class=&#34;tg-0lax&#34;&gt;1%&lt;/th&gt;
    &lt;th class=&#34;tg-0lax&#34;&gt;5%&lt;/th&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;th class=&#34;tg-0lax&#34;&gt;0.1&lt;/th&gt;
    &lt;td class=&#34;tg-0lax&#34;&gt;0.95&lt;/td&gt;
    &lt;td class=&#34;tg-0lax&#34;&gt;0&lt;/td&gt;
    &lt;td class=&#34;tg-0lax&#34;&gt;0&lt;/td&gt;
    &lt;td class=&#34;tg-0lax&#34;&gt;0.95&lt;/td&gt;
    &lt;td class=&#34;tg-0lax&#34;&gt;0&lt;/td&gt;
    &lt;td class=&#34;tg-0lax&#34;&gt;0&lt;/td&gt;
    &lt;td class=&#34;tg-0lax&#34;&gt;0.94&lt;/td&gt;
    &lt;td class=&#34;tg-0lax&#34;&gt;0&lt;/td&gt;
    &lt;td class=&#34;tg-0lax&#34;&gt;0&lt;/td&gt;
    &lt;td class=&#34;tg-0lax&#34;&gt;0.93&lt;/td&gt;
    &lt;td class=&#34;tg-0lax&#34;&gt;0&lt;/td&gt;
    &lt;td class=&#34;tg-0lax&#34;&gt;0&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;th class=&#34;tg-0lax&#34;&gt;1&lt;/th&gt;
    &lt;td class=&#34;tg-0lax&#34;&gt;0.94&lt;/td&gt;
    &lt;td class=&#34;tg-0lax&#34;&gt;0&lt;/td&gt;
    &lt;td class=&#34;tg-0lax&#34;&gt;0&lt;/td&gt;
    &lt;td class=&#34;tg-0lax&#34;&gt;0.94&lt;/td&gt;
    &lt;td class=&#34;tg-0lax&#34;&gt;0&lt;/td&gt;
    &lt;td class=&#34;tg-0lax&#34;&gt;0&lt;/td&gt;
    &lt;td class=&#34;tg-0lax&#34;&gt;&lt;b&gt;0.92&lt;/b&gt;&lt;/td&gt;
    &lt;td class=&#34;tg-0lax&#34;&gt;0&lt;/td&gt;
    &lt;td class=&#34;tg-0lax&#34;&gt;&lt;b&gt;6&lt;/b&gt;&lt;/td&gt;
    &lt;td class=&#34;tg-0lax&#34;&gt;&lt;b&gt;0.91&lt;/b&gt;&lt;/td&gt;
    &lt;td class=&#34;tg-0lax&#34;&gt;0&lt;/td&gt;
    &lt;td class=&#34;tg-0lax&#34;&gt;&lt;b&gt;94&lt;/b&gt;&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;th class=&#34;tg-0lax&#34;&gt;10&lt;/th&gt;
    &lt;td class=&#34;tg-0lax&#34;&gt;0.94&lt;/td&gt;
    &lt;td class=&#34;tg-0lax&#34;&gt;0&lt;/td&gt;
    &lt;td class=&#34;tg-0lax&#34;&gt;0&lt;/td&gt;
    &lt;td class=&#34;tg-0lax&#34;&gt;&lt;b&gt;0.87&lt;/b&gt;&lt;/td&gt;
    &lt;td class=&#34;tg-0lax&#34;&gt;0&lt;/td&gt;
    &lt;td class=&#34;tg-0lax&#34;&gt;&lt;b&gt;1&lt;/b&gt;&lt;/td&gt;
    &lt;td class=&#34;tg-0lax&#34;&gt;0.81&lt;/td&gt;
    &lt;td class=&#34;tg-0lax&#34;&gt;0&lt;/td&gt;
    &lt;td class=&#34;tg-0lax&#34;&gt;20&lt;/td&gt;
    &lt;td class=&#34;tg-0lax&#34;&gt;0.80&lt;/td&gt;
    &lt;td class=&#34;tg-0lax&#34;&gt;0&lt;/td&gt;
    &lt;td class=&#34;tg-0lax&#34;&gt;109&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;th class=&#34;tg-0lax&#34;&gt;100&lt;/th&gt;
    &lt;td class=&#34;tg-0lax&#34;&gt;0.93&lt;/td&gt;
    &lt;td class=&#34;tg-0lax&#34;&gt;0&lt;/td&gt;
    &lt;td class=&#34;tg-0lax&#34;&gt;0&lt;/td&gt;
    &lt;td class=&#34;tg-0lax&#34;&gt;&lt;b&gt;&lt;font color=&#34;red&#34;&gt;0.61&lt;/font&gt;&lt;/b&gt;&lt;/td&gt;
    &lt;td class=&#34;tg-0lax&#34;&gt;&lt;b&gt;&lt;font color=&#34;red&#34;&gt;1&lt;/font&gt;&lt;/b&gt;&lt;/td&gt;
    &lt;td class=&#34;tg-0lax&#34;&gt;32&lt;/td&gt;
    &lt;td class=&#34;tg-0lax&#34;&gt;&lt;b&gt;&lt;font color=&#34;red&#34;&gt;0.49&lt;/font&gt;&lt;/b&gt;&lt;/td&gt;
    &lt;td class=&#34;tg-0lax&#34;&gt;&lt;b&gt;&lt;font color=&#34;red&#34;&gt;30&lt;/font&gt;&lt;/td&gt;
    &lt;td class=&#34;tg-0lax&#34;&gt;281&lt;/td&gt;
    &lt;td class=&#34;tg-0lax&#34;&gt;&lt;b&gt;&lt;font color=&#34;red&#34;&gt;0.48&lt;/font&gt;&lt;/b&gt;&lt;/td&gt;
    &lt;td class=&#34;tg-0lax&#34;&gt;&lt;b&gt;&lt;font color=&#34;red&#34;&gt;11&lt;/font&gt;&lt;/b&gt;&lt;/td&gt;
    &lt;td class=&#34;tg-0lax&#34;&gt;202&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;th class=&#34;tg-0lax&#34;&gt;1000&lt;/th&gt;
    &lt;td class=&#34;tg-0lax&#34;&gt;&lt;b&gt;0.59&lt;/b&gt;&lt;/td&gt;
    &lt;td class=&#34;tg-0lax&#34;&gt;0&lt;/td&gt;
    &lt;td class=&#34;tg-0lax&#34;&gt;&lt;b&gt;11&lt;/b&gt;&lt;/td&gt;
    &lt;td class=&#34;tg-0lax&#34;&gt;0.06&lt;/td&gt;
    &lt;td class=&#34;tg-0lax&#34;&gt;13&lt;/td&gt;
    &lt;td class=&#34;tg-0lax&#34;&gt;359&lt;/td&gt;
    &lt;td class=&#34;tg-0lax&#34;&gt;0.00&lt;/td&gt;
    &lt;td class=&#34;tg-0lax&#34;&gt;28&lt;/td&gt;
    &lt;td class=&#34;tg-0lax&#34;&gt;416&lt;/td&gt;
    &lt;td class=&#34;tg-0lax&#34;&gt;0.07&lt;/td&gt;
    &lt;td class=&#34;tg-0lax&#34;&gt;22&lt;/td&gt;
    &lt;td class=&#34;tg-0lax&#34;&gt;383&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr bgcolor=&#34;yellow&#34;&gt;
    &lt;th class=&#34;tg-0lax&#34;&gt;&amp;infin;&lt;/th&gt;
    &lt;td class=&#34;tg-0lax&#34;&gt;&lt;font color=&#34;darkred&#34;&gt;0.00&lt;/font&gt;&lt;/td&gt;
    &lt;td class=&#34;tg-0lax&#34;&gt;&lt;font color=&#34;darkred&#34;&gt;155&lt;/font&gt;&lt;/td&gt;
    &lt;td class=&#34;tg-0lax&#34;&gt;&lt;font color=&#34;darkred&#34;&gt;2667&lt;/font&gt;&lt;/td&gt;
    &lt;th class=&#34;tg-0lax&#34; colspan=&#34;9&#34;&gt;&lt;span style=&#34;font-weight:normal&#34;&gt;No privacy noise added.&lt;/span&gt;&lt;/th&gt;
  &lt;/tr&gt;
&lt;/table&gt;&lt;/p&gt;

&lt;p&gt;Bargav Jayaraman talked about this work at the &lt;a href=&#34;https://dcaps.info/2019-2-25.html&#34;&gt;&lt;em&gt;DC-Area Anonymity, Privacy, and Security Seminar&lt;/em&gt;&lt;/a&gt; (25 February 2019) at the University of Maryland:&lt;/p&gt;

&lt;script async class=&#34;speakerdeck-embed&#34; data-id=&#34;294ac688ec6d415a9bef17a91e031459&#34; data-ratio=&#34;1.77777777777778&#34; src=&#34;//speakerdeck.com/assets/embed.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;Paper: &lt;a href=&#34;https://arxiv.org/abs/1902.08874&#34;&gt;&lt;em&gt;When Relaxations Go Bad: &amp;ldquo;Differentially-Private&amp;rdquo; Machine Learning&lt;/em&gt;&lt;/a&gt;&lt;br /&gt;
Code: &lt;a href=&#34;https://github.com/bargavj/EvaluatingDPML&#34;&gt;https://github.com/bargavj/EvaluatingDPML&lt;/a&gt;)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Violations of Children’s Privacy Laws</title>
      <link>//jeffersonswheel.org/violations-of-childrens-privacy-laws/</link>
      <pubDate>Sun, 16 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>//jeffersonswheel.org/violations-of-childrens-privacy-laws/</guid>
      <description>&lt;p&gt;The New York Times has an article, &lt;a href=&#34;https://www.nytimes.com/interactive/2018/09/12/technology/kids-apps-data-privacy-google-twitter.html&#34;&gt;&lt;em&gt;How Game Apps That Captivate Kids Have Been Collecting Their Data&lt;/em&gt;&lt;/a&gt; about a lawsuit the state of New Mexico is bringing against app markets (including Google) that allow apps presented as being for children in the Play store to violate COPPA rules and mislead users into tracking children. The lawsuit stems from a study led by Serge Egleman’s group at UC Berkeley that analyzed COPPA violations in children’s apps. Serge was an undergraduate student here (back in the early 2000s) &amp;#8211; one of the things he did as a undergraduate was successfully sue a spammer.&lt;/p&gt;
&lt;p&gt;The original paper about the study: &lt;a href=&#34;https://blues.cs.berkeley.edu/wp-content/uploads/2018/04/popets-2018-0021.pdf&#34;&gt;“Won’t Somebody Think of the Children?” Examining COPPA Compliance at Scale&lt;/a&gt;, Irwin Reyes, Primal Wijesekera, Joel Reardon, Amit Elazari Bar On, Abbas Razaghpanah, Narseo Vallina-Rodriguez, and Serge Egelman. Proceedings on Privacy Enhancing Technologies (PETS) 2018.&lt;/p&gt;
&lt;p&gt;&lt;center&gt;&lt;br /&gt;
&lt;img src=&#34;https://static01.nyt.com/images/2018/09/13/autossell/13Kidapps2/13Kidapps2-superJumbo.jpg&#34; width=&#34;80%&#34;&gt;&lt;br /&gt;
&lt;div class=&#34;caption&#34;&gt;
Serge Egelman, a researcher with the International Computer Science Institute and the University of California, Berkeley, helped lead the study of nearly 6,000 children’s Android apps&lt;br /&gt;
&lt;/div&gt;
&lt;/center&gt;&lt;/p&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>USENIX Security 2018</title>
      <link>//jeffersonswheel.org/usenix-security-2018/</link>
      <pubDate>Sun, 19 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>//jeffersonswheel.org/usenix-security-2018/</guid>
      <description>&lt;p&gt;Three SRG posters were presented at &lt;a
href=&#34;https://www.usenix.org/conference/usenixsecurity18/poster-session&#34;&gt;USENIX
Security Symposium 2018&lt;/a&gt; in Baltimore, Maryland:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Nathaniel Grevatt (&lt;em&gt;GDPR-Compliant Data Processing: Improving
Pseudonymization with Multi-Party Computation&lt;/em&gt;)&lt;/li&gt;
&lt;li&gt;Matthew Wallace and Parvesh Samayamanthula (&lt;em&gt;Deceiving Privacy Policy Classifiers with Adversarial Examples&lt;/em&gt;)&lt;/li&gt;
&lt;li&gt;Guy Verrier (&lt;em&gt;How is GDPR Affecting Privacy Policies?&lt;/em&gt;, joint with Haonan Chen and Yuan
Tian)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;center&gt;&lt;/p&gt;
&lt;table width=&#34;85%&#34;&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;
&lt;a href=&#34;//jeffersonswheel.org/images/usenix2018/IMG_20180816_190616-2.jpg&#34;&gt;&lt;img align=&#34;center&#34; src=&#34;//jeffersonswheel.org/images/usenix2018/IMG_20180816_190616.jpg&#34; height=220&gt;
&lt;/td&gt;
&lt;td href=&#34;//jeffersonswheel.org/images/usenix2018/IMG_20180816_190626-2.jpg&#34;&gt;&lt;img align=&#34;center&#34; src=&#34;//jeffersonswheel.org/images/usenix2018/IMG_20180816_190626.jpg&#34; height=220&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;
&lt;a href=&#34;//jeffersonswheel.org/images/usenix2018/IMG_20180816_192620-2.jpg&#34;&gt;&lt;img align=&#34;center&#34; src=&#34;//jeffersonswheel.org/images/usenix2018/IMG_20180816_192620.jpg&#34; height=220&gt;
&lt;/td&gt;
&lt;td href=&#34;//jeffersonswheel.org/images/usenix2018/IMG_20180816_192646-2.jpg&#34;&gt;&lt;img align=&#34;center&#34; src=&#34;//jeffersonswheel.org/images/usenix2018/IMG_20180816_192646.jpg&#34; height=220&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;p&gt;There were also a surprising number of appearances by an unidentified unicorn:&lt;br /&gt;
&lt;center&gt;&lt;/p&gt;
&lt;blockquote class=&#34;twitter-tweet&#34; data-lang=&#34;en&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;Your poster may have made the cut for the &lt;a href=&#34;https://twitter.com/hashtag/usesec18?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#usesec18&lt;/a&gt; Poster Reception, but has it received the approval of a tiny, adorable unicorn? &lt;a href=&#34;https://twitter.com/UVA?ref_src=twsrc%5Etfw&#34;&gt;@UVA&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/seenatusesec18?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#seenatusesec18&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/girlswhocode?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#girlswhocode&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/futurecomputerscientist?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#futurecomputerscientist&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hashtag/dreambig?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#dreambig&lt;/a&gt; &lt;a href=&#34;https://t.co/bZOO6lYLXK&#34;&gt;pic.twitter.com/bZOO6lYLXK&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&amp;mdash; USENIX Security (@USENIXSecurity) &lt;a href=&#34;https://twitter.com/USENIXSecurity/status/1030215384505491456?ref_src=twsrc%5Etfw&#34;&gt;August 16, 2018&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;br /&gt;
&lt;/center&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>