<!doctype html>
<html class="no-js" lang="en-us">
  <head>
	<meta name="generator" content="Hugo 0.17" />
    <meta charset="utf-8">
    <title>Jefferson&#39;s Wheel</title>
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    <link rel="stylesheet" href="//jeffersonswheel.org/css/foundation.min.css">
    <link rel="stylesheet" href="//jeffersonswheel.org/css/highlight.min.css">
    <link rel="stylesheet" href="//jeffersonswheel.org/css/font-awesome.min.css">
    <link rel="stylesheet" href="//jeffersonswheel.org/css/academicons.min.css">
    <link rel="stylesheet" href="//jeffersonswheel.org/css/fonts.css">
    <link rel="stylesheet" href="//jeffersonswheel.org/css/finite.css">
    <link rel="shortcut icon" href="/rotunda.png">  
    
  </head>
  <body>
      
    <header>
      <nav class="nav-bar">
	
	  <div class="title-bar" data-responsive-toggle="site-menu" data-hide-for="medium">	      
	    <button class="site-hamburger" type="button" data-toggle>
	      <i class="fa fa-bars fa-lg" aria-hidden="true"></i>
	    </button>
	    <div class="title-bar-title site-title">
	      <a href="//jeffersonswheel.org/">Jefferson&#39;s Wheel</a>
	    </div>
	    <div class="title-bar-right pull-right">
	      
	      
	    </div>
	  </div>
	    
	  
	    <div class="top-bar" id="site-menu" >	      
	      <div class="top-bar-title show-for-medium site-title">
		<a href="//jeffersonswheel.org/">Jefferson&#39;s Wheel</a>
	      </div>
	      <div class="top-bar-left">
		<ul class="menu vertical medium-horizontal">
		  
		  
		</ul>
	      </div>
	      <div class="top-bar-right show-for-medium">
		
	         <p class="groupstyle">Security and Privacy Research</br>at the University of Virginia</p>
		
	      </div>
	    </div>
	  
	</nav>
      
    </header>
    
    <main>
      





   <div class="container">       
   <div class="sidebar">
University of Virginia <br>
Security Research Group
   </p>
<p align="center"><img src="/images/jwlogo-transparent.png" width="90%">

</p>
   <p>
Director: <a href="//www.cs.virginia.edu/evans">David Evans</a>
   </p>
   <p>
   <a href="//www.cs.virginia.edu/evans/students"><b>Team</b></a></br>
   <a href="//www.cs.virginia.edu/evans/pubs"><b>Publications</b></a><br>
   </p>
   <p>
   <a href="https://uvasrg.slack.com/"><b>Join Slack Group</b></a>
   </p>

   <p class="nogap">
   <b><a href="/post/">Recent News</a></b>
   </p>
   
   <div class="posttitle">
      <a href="/cantors-no-longer-lost-proof/">Cantor&#39;s (No Longer) Lost Proof</a>


   </div>
   
   <div class="posttitle">
      <a href="/fosad2019/">FOSAD Trustworthy Machine Learning Mini-Course</a>


   </div>
   
   <div class="posttitle">
      <a href="/usenix-security-symposium-2019/">USENIX Security Symposium 2019</a>


   </div>
   
   <div class="posttitle">
      <a href="/google-security-and-privacy-workshop/">Google Security and Privacy Workshop</a>


   </div>
   
   <div class="posttitle">
      <a href="/brink-essay-ai-systems-are-complex-and-fragile.-here-are-four-key-risks-to-understand./">Brink Essay: AI Systems Are Complex and Fragile. Here Are Four Key Risks to Understand.</a>


   </div>
   
   <div class="more"><a href="/post/">More...</a></div>
   </p>
   <p>
<a href="/awards.html"><b>Awards</b></a>
    <p>
<div class="more"><a href="/oldindex.html">Old Site</a></div>
    </div>
    <div class="content">

    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
           <div class="row">
    <div class="column small-25 medium-7">
 Our research seeks to empower individuals and organizations to
control how their data is used.  We use techniques from cryptography,
programming languages, machine learning, operating systems, and other
areas to both understand and improve the security of computing as
practiced today, and as envisioned in the future.  </p> 
 <p> Everyone is welcome at our research group meetings
(most Fridays at 11am, but join the slack group for announcements). To
get announcements, join our <a
href="https://uvasrg.slack.com/signup">Slack Group</a> (any
<em>@virginia.edu</em> email address can join themsleves, or email me
to request an invitation). </p>
   </div>
    <div class="column small-5 medium-5">
<center> <a
href="/images/srg2017/IMG_20171212_135015.jpg"><img
src="/images/srg2017/IMG_20171212_135015-2.jpg" alt="SRG lunch"
width=98%></a></br> <b>Security Research Group Lunch</b> <font size="-1">(12&nbsp;December&nbsp;2017)</font><br> 
<div class="smallcaption">
<a href="https://hainali.github.io/">Haina&nbsp;Li</a>, Felix&nbsp;Park, <a
href="https://sites.google.com/site/mahmadjonas/">Mainuddin&nbsp;Jonas</a>,
<A
href="https://www.linkedin.com/in/anant-kharkar-502433b9">Anant&nbsp;Kharkar</a>,
<a
href="http://dblp2.uni-trier.de/pers/hd/s/Shezan:Faysal_Hossain">Faysal&nbsp;Hossain&nbsp;Shezan</a>, <A href="https://fsuya.org/">Fnu&nbsp;Suya</a>, <A
href="https://www.cs.virginia.edu/evans">David&nbsp;Evans</a>, <a
href="https://www.yuantiancmu.com/">Yuan&nbsp;Tian</a>, <a
href="//www.cs.columbia.edu/~riley/">Riley&nbsp;Spahn</a>, <a
href="//www.cs.virginia.edu/~wx4ed/">Weilin&nbsp;Xu</a>, <a
href="https://github.com/gjverrier">Guy&nbsp;"Jack"&nbsp;Verrier</a> </font>
</center> </p>
   </div>
</div>

<div class="mainsection">Projects</div>

<p><div class="row">
    <div class="column small-10 medium-5">
<b>Adversarial Machine Learning</b><br> <a
href="//www.evademl.org/">EvadeML</a></p>

<p><b>Secure Multi-Party Computation</b><br>
<a href="//www.oblivc.org/">Obliv-C</a> &middot; <a href="//www.mightbeevil.org/">MightBeEvil</a>
    </div>
    <div class="column small-14 medium-7">
<b>Web and Mobile Security</b><br> <a
href="//www.scriptinspector.org/">ScriptInspector</a> &middot; <a
href="//www.ssoscan.org/">SSOScan</a></p>

<p><b><a href="//www.cs.virginia.edu/evans/research.html">Past Projects</b><br> <font size="-1"> <a
<a href="//www.splint.org/">Splint</a> &middot;
<a href="//wwww.cs.virginia.edu/perracotta">Perracotta</a> &middot;
<a href="//www.cs.virginia.edu/nvariant/">N-Variant Systems</a> &middot;
<a href="//www.cs.virginia.edu/physicrypt/">Physicrypt</a> &middot;
<a href="//www.cs.virginia.edu/evans/research.html">More&hellip;</a>
</font>
</div>
</div></p>

        
    
  

    <div class="mainsection">Recent Posts</div>

    
    <h2><a href="/cantors-no-longer-lost-proof/">Cantor&#39;s (No Longer) Lost Proof</a></h2>
<div class="post-metadata">
  <span class="post-date">
    <time datetime="2019-09-26 00:00:00 &#43;0000 UTC" itemprop="datePublished">26 September 2019</time>
  </span>
  
  
  
  <span class="post-tags">
    <span class="nowrap"><i class="fa fa-tags"></i>
    
    <a class="post-tag" href="//jeffersonswheel.org/tags/uncountability">uncountability</a>,</span> 
    
    <a class="post-tag" href="//jeffersonswheel.org/tags/teaching">teaching</a>, 
    
    <a class="post-tag" href="//jeffersonswheel.org/tags/history">history</a>
    
  </span>
  
  
</div>

      <div class="post-body" itemprop="articleBody">
        <p>In preparing to cover Cantor&rsquo;s proof of different infinite set
cardinalities (one of my all-time favorite topics!) in our <a href="https://uvatoc.github.io/class4/">theory of
computation course</a>, I found various
conflicting accounts of what Cantor originally proved. So, I figured
it would be easy to search the web to find the original proof.</p>

<p>Shockingly, at least as far as I could find<sup>1</sup>, it didn&rsquo;t
 exist on the web! The closest I could find was in Google Books the
 1892 volume of the <em>J&auml;hresbericht Deutsche
 Mathematiker-Vereinigung</em> (which many of the references pointed
 to), but in fact not the first value of that journal which contains
 the actual proof.</p>

<p>Normally, of course, when something doesn&rsquo;t turn up in DuckDuckGo
searches, that means it doesn&rsquo;t exist, but for a document this old, I
figured it was worth actually visiting a library. (Okay, nothing quite
so radical as going to a physical library! By visit, I mean, going to
the website for the university library and searching there.)</p>

<p>So, I tried submitting the form our library has, requesting <em>Uber eine
elementare Frage der Mannigfaltigkeits-lehre</em> by G. Cantor from the
1891 journal. I didn&rsquo;t notice the scan request until after submitting,
so I tried again, checking the box to request a PDF scan.</p>

<p>I was delighted a few days later to receive this email:</p>

<p><center><a href="/images/cantor/email.png"><img src="/images/cantor/email.png" width="80%" style="box-shadow: 10px 10px 5px grey;"></a>
</center></p>

<p>And, indeed the link went to a scan of Cantor&rsquo;s original proof (<a href="/docs/cantor-proof.pdf">PDF</a>):</p>

<p><center>
<embed src="/docs/cantor-proof.pdf" width="80%" height="500" 
 type="application/pdf">
</center></p>

<p>The really cool thing is about two days later I happened to wander
into the printer room, and saw a strange object in my mailbox with a
nice musty smell.</p>

<p>Apparently, the original request I&rsquo;d submitted to the library had gone
through, and I found myself starting at an 1891 edition of a German
math journal!</p>

<p><center>
<a href="/images/cantor/IMG_20190919_083500.jpg"><img src="/images/cantor/IMG_20190919_083500-2.jpg" width="50%"></a>
</center></p>

<p>And on pages 75-78, Cantor&rsquo;s original published proof!</p>

<p><center>
<a href="/images/cantor/IMG_20190919_083511.jpg"><img src="/images/cantor/IMG_20190919_083511-2.jpg" width="80%"></a>
</center></p>

<p><center>
<a href="/images/cantor/IMG_20190919_083522.jpg"><img src="/images/cantor/IMG_20190919_083522-2.jpg" width="80%"></a>
</center></p>

<p><center>
<a href="/images/cantor/IMG_20190919_083526.jpg"><img src="/images/cantor/IMG_20190919_083526-2.jpg" width="80%"></a>
</center></p>

<p><center>
<a href="/images/cantor/IMG_20190919_083526.jpg"><img src="/images/cantor/IMG_20190919_083526-2.jpg" width="80%"></a>
</center></p>

<p><center>
<a href="/images/cantor/IMG_20190919_083549.jpg"><img src="/images/cantor/IMG_20190919_083549-2.jpg" width="80%"></a>
</center></p>

<p>I don&rsquo;t read German, but the last line is well worth translating:</p>

<p><center>
<a href="/images/cantor/translation.png">
<img src="/images/cantor/translation.png" width="80%"></a>
</center></p>

<p>From now on, whenever its hard to come up with a good conclusion to a
paper, this one always works.</p>

<p>I believe our library&rsquo;s policy is that (at least for faculty) when you
check out a book you can keep it until the next person requests
it. So, I&rsquo;ll be holding on to this one until then. When prospective
high school students visit UVA, they often ask to see all the cool
cutting edge technology we use in our research. I&rsquo;ll be happy to show
them three of the coolest things I have in my office: an abacus, an
Apple II, and now, an 1891 math journal.</p>

<hr>

<ol>
<li>Apparently I wasn&rsquo;t very good at searching then. In writing this
post, I tried a new search and found a great post with both the
original German and an English translation: <a
href="https://www.jamesrmeyer.com/infinite/cantors-original-1891-proof.html"><em>Cantor’s
Original 1891 Diagonal proof</em></a> by James Meyer.</li>
</ol>

      </div>
<hr class="post-separator"></hr>

    
    <h2><a href="/fosad2019/">FOSAD Trustworthy Machine Learning Mini-Course</a></h2>
<div class="post-metadata">
  <span class="post-date">
    <time datetime="2019-08-28 00:00:00 &#43;0000 UTC" itemprop="datePublished">28 August 2019</time>
  </span>
  
  
  
  <span class="post-tags">
    <span class="nowrap"><i class="fa fa-tags"></i>
    
    <a class="post-tag" href="//jeffersonswheel.org/tags/privacy">privacy</a>,</span> 
    
    <a class="post-tag" href="//jeffersonswheel.org/tags/adversarial-machine-learning">adversarial machine learning</a>
    
  </span>
  
  
</div>

      <div class="post-body" itemprop="articleBody">
        

<p>I taught a mini-course on <em>Trustworthy Machine Learning</em> at the <a href="http://www.sti.uniurb.it/events/fosad19/"><em>19th
International School on Foundations of Security Analysis and
Design</em></a> in Bertinoro, Italy.</p>

<p><center><a href="/images/bertinoro-big.jpg"><img src="/images/bertinoro.jpg" width="90%"></a></center></p>

<p>Slides from my three (two-hour) lectures are posted below, along with
some links to relevant papers and resources.</p>

<h2 id="class-1-introduction-attacks">Class 1: Introduction/Attacks</h2>

<p><center>
<script async class="speakerdeck-embed" data-id="0ad1775bcc244876ac4df1880a864e78" data-ratio="1.77777777777778" src="//speakerdeck.com/assets/embed.js"></script>
</center></p>

<p>The PDF malware evasion attack is described in this paper:
<blockquote>
Weilin Xu, Yanjun Qi, and David Evans.
<em><a href="https://www.cs.virginia.edu/evans/pubs/ndss2016/">Automatically Evading Classifiers: A Case Study on PDF Malware Classifiers</a></em>.
<a href="https://www.internetsociety.org/events/ndss-symposium-2016"><em>Network and Distributed System Security Symposium</em></a> (NDSS). San Diego, CA. 21-24 February 2016. [<a href="https://www.cs.virginia.edu/evans/pubs/ndss2016/evademl.pdf">PDF</a>] [<a href="https://evademl.org/gpevasion/">EvadeML.org</a>]
</blockquote></p>

<h2 id="class-2-defenses">Class 2: Defenses</h2>

<p><center>
<script async class="speakerdeck-embed" data-id="cf560cce9e4b418397d2df3429ddc8f9" data-ratio="1.77777777777778" src="//speakerdeck.com/assets/embed.js"></script>
</center></p>

<p>This paper describes the feature squeezing framework:
<blockquote>
Weilin Xu, David Evans, and Yanjun Qi. <a href="https://www.cs.virginia.edu/evans/pubs/ndss2018/">Feature Squeezing: Detecting Adversarial Examples in Deep Neural Networks</a></em>. In <a href="https://www.ndss-symposium.org/ndss2018/"><em>2018 Network and Distributed System Security Symposium</em></a>. 18-21 February, San Diego, California. [<a href="https://evademl.org/docs/featuresqueezing.pdf">PDF</a>] [<a href="https://evademl.org/squeezing/">Project</a>]
</blockquote>
This paper introduces cost-sensitive robustness:
<blockquote>
Xiao Zhang and David Evans. <em><a href="https://www.cs.virginia.edu/evans/pubs/iclr2019/">Cost-Sensitive Robustness against Adversarial Examples</a></em>. In <a href="https://iclr.cc/Conferences/2019"><em>Seventh International Conference on Learning Representations</em></a> (ICLR). New Orleans. May 2019. [<a
href="https://arxiv.org/abs/1810.09225">arXiv</a>] [<a
href="https://openreview.net/forum?id=BygANhA9tQ">OpenReview</a>] [<a href="https://evademl.org/docs/cost-sensitive-robustness.pdf">PDF</a>]
</blockquote></p>

<h2 id="class-3-privacy">Class 3: Privacy</h2>

<p><center>
<script async class="speakerdeck-embed" data-id="8b378ae0ac2c4a7588016311d1d76ef8" data-ratio="1.77777777777778" src="//speakerdeck.com/assets/embed.js"></script>
</center></p>

<p>This (free) book provides an introduction to secure multi-party computation:
<blockquote>
David Evans, Vladimir Kolesnikov and Mike Rosulek. <a href="https://securecomputation.org/"><em>A Pragmatic Introduction to Secure Multi-Party Computation</em></a>. NOW Publishers, December 2018. <a href="https://securecomputation.org/docs/pragmaticmpc.pdf"><a href="Full Text">PDF</a></a>
</blockquote></p>

<p><a href="https://oblivc.org">OblivC.org</a> is an open-source tool for
building secure multi-party computations from high-level (extended C)
code.</p>

<p>This paper describes our work on integrating differential privacy and multi-party computation:
<blockquote>
Bargav Jayaraman, Lingxiao Wang, David Evans and Quanquan
Gu. <em><a href="https://www.cs.virginia.edu/evans/pubs/neurips2018/">Distributed Learning without Distress:
    Privacy-Preserving Empirical Risk Minimization</a></em>. In <a href="https://nips.cc/Conferences/2018/">32<sup>nd</sup>
<em>Conference on Neural Information Processing Systems</em></a>
(NeurIPS). Montreal, Canada. December 2018. [<a
    href="https://www.cs.virginia.edu/evans/pubs/neurips2018/neurips2018.pdf">PDF</a>] [<a
    href="https://youtu.be/rwyWiDyVmjE">Video Summary</a>]
</blockquote></p>

<p>This paper summarizes our work on evaluating the privacy-utility tradeoffs for machine learning:
<blockquote>
Bargav Jayaraman and David Evans. <em><a href="https://www.cs.virginia.edu/evans/pubs/usenix2019/">Evaluating Differentially Private Machine Learning in Practice</a></em>. In <a
href="https://www.usenix.org/conference/usenixsecurity19">28<sup>th</sup>
USENIX Security Symposium</em></a>. Santa&nbsp;Clara. August 2019.
[<a href="usenix2019/evaluatingdp.pdf">PDF</a>]
[<a href="https://arxiv.org/abs/1902.08874">arXiv</a>]
[<A href="https://github.com/bargavj/EvaluatingDPML">code</a>]
</blockquote></p>

      </div>
<hr class="post-separator"></hr>

    
    <h2><a href="/usenix-security-symposium-2019/">USENIX Security Symposium 2019</a></h2>
<div class="post-metadata">
  <span class="post-date">
    <time datetime="2019-08-26 00:00:00 &#43;0000 UTC" itemprop="datePublished">26 August 2019</time>
  </span>
  
  
  
  <span class="post-tags">
    <span class="nowrap"><i class="fa fa-tags"></i>
    
    <a class="post-tag" href="//jeffersonswheel.org/tags/privacy">privacy</a>,</span> 
    
    <a class="post-tag" href="//jeffersonswheel.org/tags/privacy-preserving-machine-learning">privacy-preserving machine learning</a>, 
    
    <a class="post-tag" href="//jeffersonswheel.org/tags/bargav-ayaraman">Bargav ]ayaraman</a>, 
    
    <a class="post-tag" href="//jeffersonswheel.org/tags/sam-havron">Sam Havron</a>, 
    
    <a class="post-tag" href="//jeffersonswheel.org/tags/serge-egelman">Serge Egelman</a>
    
  </span>
  
  
</div>

      <div class="post-body" itemprop="articleBody">
        <p>Bargav Jayaraman presented our paper on <a href="https://arxiv.org/abs/1902.08874"><em>Evaluating Differentially Private Machine Learning in Practice</em></a> at the <a
href="https://www.usenix.org/conference/usenixsecurity19">28<sup>th</sup>
USENIX Security Symposium</em></a> in Santa Clara, California.</p>

<p><center>
<script async class="speakerdeck-embed" data-id="dfdd40e4ba2b46e1baee68219df82de7" data-ratio="1.29456384323641" src="//speakerdeck.com/assets/embed.js"></script>
</center></p>

<p><center><img src="/images/usenix2019/bargav.jpg" width=80%"></center></p>

<p>Summary by Lea Kissner:
<center>
<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Hey it&#39;s the results! <a href="https://t.co/ru1FbkESho">pic.twitter.com/ru1FbkESho</a></p>&mdash; Lea Kissner (@LeaKissner) <a href="https://twitter.com/LeaKissner/status/1162518239177371648?ref_src=twsrc%5Etfw">August 17, 2019</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</center></p>

<p>Also, great to see several UVA folks at the conference including:</p>

<ul>
<li><a href="https://havron.dev">Sam Havron</a> (BSCS 2017, now a PhD student at
Cornell) presented a paper on the work he and his colleagues have
done on <a href="https://havron.dev/pubs/clinicalsec.pdf">computer security for victims of intimate partner violence</a>.</li>
</ul>

<p><center><img src="/images/usenix2019/havron.jpg" width=80%"></center></p>

<ul>
<li><p><a href="https://www.guanotronic.com/~serge/">Serge Egelman</a> (BSCS 2004) was an author on the paper <a href="https://www.usenix.org/conference/usenixsecurity19/presentation/reardon"><em>50 Ways to Leak Your Data: An
Exploration of Apps&rsquo; Circumvention of the Android Permissions
System</em></a>
(which was recognized by a Distinguished Paper Award). His paper in
SOUPS on <a href="https://www.usenix.org/system/files/soups2019-frik.pdf"><em>Privacy and Security Threat Models and Mitigation
Strategies of Older
Adults</em></a> was highlighted in Alex Stamos&rsquo; excellent talk.</p></li>

<li><p><a href="https://www.ytian.info/">Yuan Tian</a> (UVA professor) presented her work on Chinese password guessability (since the student author who was planning to present was unfortunately unable to obtain a visa in time). Chinese passwords are different from those of English speakers in many interesting ways, but everyone agrees that <code>123456</code> is a great password.</p></li>
</ul>

<p><center><img src="/images/usenix2019/yuantian.jpg" width=80%"></center></p>

      </div>
<hr class="post-separator"></hr>

    
    <h2><a href="/google-security-and-privacy-workshop/">Google Security and Privacy Workshop</a></h2>
<div class="post-metadata">
  <span class="post-date">
    <time datetime="2019-08-25 00:00:00 &#43;0000 UTC" itemprop="datePublished">25 August 2019</time>
  </span>
  
  
  
  <span class="post-tags">
    <span class="nowrap"><i class="fa fa-tags"></i>
    
    <a class="post-tag" href="//jeffersonswheel.org/tags/adversarial-machine-learning">adversarial machine learning</a>,</span> 
    
    <a class="post-tag" href="//jeffersonswheel.org/tags/google">Google</a>
    
  </span>
  
  
</div>

      <div class="post-body" itemprop="articleBody">
        <p>I presented a short talk at a workshop at Google on <em>Adversarial ML: Closing Gaps between Theory and Practice</em> (mostly fun for the <a href="https://www.youtube.com/watch?v=TVmjjfTvnFs">movie of me trying to solve Google&rsquo;s CAPTCHA</a> on the last slide):</p>

<iframe src="https://docs.google.com/presentation/d/e/2PACX-1vTKeMueFNQPz0Pms4EGKoYOXVEg92IBi55babPKG5WRrhHRR2PmIYwZIyLsZ11ucKSahqjjp3Zxd5i3/embed?start=true&loop=false&delayms=3000" frameborder="0" width="960" height="569" allowfullscreen="true" mozallowfullscreen="true" webkitallowfullscreen="true"></iframe>

<p>Getting the actual screencast to fit into the limited time for this talk challenged the limits of my video editing skills.</p>

<p><center>
<img src="/images/googledonuts.jpg" width="90%"><br>
I can say with some confidence, Google does donuts much better than they <a href="https://freedom-to-tinker.com/2019/08/23/deconstructing-googles-excuses-on-tracking-protection/">do cookies</a>!
</center></p>

      </div>
<hr class="post-separator"></hr>

    
    <h2><a href="/brink-essay-ai-systems-are-complex-and-fragile.-here-are-four-key-risks-to-understand./">Brink Essay: AI Systems Are Complex and Fragile. Here Are Four Key Risks to Understand.</a></h2>
<div class="post-metadata">
  <span class="post-date">
    <time datetime="2019-07-09 00:00:00 &#43;0000 UTC" itemprop="datePublished">9 July 2019</time>
  </span>
  
  
  
  <span class="post-tags">
    <span class="nowrap"><i class="fa fa-tags"></i>
    
    <a class="post-tag" href="//jeffersonswheel.org/tags/adversarial-machine-learning">adversarial machine learning</a>,</span> 
    
    <a class="post-tag" href="//jeffersonswheel.org/tags/privacy">privacy</a>, 
    
    <a class="post-tag" href="//jeffersonswheel.org/tags/fairness">fairness</a>
    
  </span>
  
  
</div>

      <div class="post-body" itemprop="articleBody">
        <p>Brink News (a publication of the <em>The Atlantic</em>) published my essay on the risks of deploying AI systems.</p>

<p><center>
<a href="https://www.brinknews.com/ai-systems-are-complex-and-fragile-here-are-four-key-risks-to-understand/"><img style="box-shadow: 10px 10px 5px grey;" src="/images/brink.png" width=90%"></a>
</center></p>

<p><span style="font-weight: 400;">Artificial intelligence technologies have the potential to transform society in positive and powerful ways. Recent studies have shown computing systems that can outperform humans at numerous once-challenging tasks, ranging from performing medical diagnoses and reviewing legal contracts to playing Go and recognizing human emotions. </span></p>
<p><span style="font-weight: 400;">Despite these successes, AI systems are fundamentally fragile — and the ways they can fail are poorly understood. When AI systems are deployed to make important decisions that impact human safety and well-being, the potential risks of abuse and misbehavior are high and need to be carefully considered and mitigated.</span></p>
<h2>What Is Deep Learning?</h2>
<p><span style="font-weight: 400;">Over the past seven decades, automatic computing has astonishingly amplified human intelligence. It can execute any information process a human understands well enough to describe precisely at a rate that is quadrillions of times faster than what any human could do. It also enables thousands of people to work together to produce systems that no individual understands.</span></p>
<p><span style="font-weight: 400;">Artificial intelligence goes beyond this: It allows machines to solve problems in ways no human understands. Instead of being programmed like traditional computing, AI systems are trained. Human engineers set up a training environment and methods, and the machine learns how to solve problems on its own. Although AI is a broad field with many different directions, much of the current excitement is focused on a narrow branch of statistical machine learning known as “deep learning,” where a model is trained to make predictions based on statistical patterns in a training data set.</span></p>
<p><span style="font-weight: 400;">In a typical training process, training data is collected, and a model is trained to recognize patterns in this data — as well as patterns in those learned patterns — in order to make predictions about new data. The resulting model can include millions of trained parameters, while providing little insight into how it works or evidence as to which patterns it has learned. It can, however, result in remarkably accurate models when the data used for training is well-distributed and correctly labeled and the data the model needs to make predictions about in deployment is similar to that training data. </span></p>
<p><span style="font-weight: 400;">When it is not, however, lots of things can go wrong.</span></p>
<h2>Dogs Also Play in the Snow</h2>
<p><span style="font-weight: 400;">Models learn patterns in the training data, but it is difficult to know if what they have learned is relevant — or just some artifact of the training data. In one famous example, a model that learned to accurately distinguish wolves and dogs </span><a href="https://www.kdd.org/kdd2016/papers/files/rfp0573-ribeiroA.pdf" target="_blank" rel="noopener noreferrer"><span style="font-weight: 400;">had actually learned nothing about animals</span></a><span style="font-weight: 400;">. Instead, what it had learned was to recognize snow, since all the training examples with snow were wolves, and the examples without snow were dogs.</span></p>
<p><span style="font-weight: 400;">In a more serious example, a PDF malware classifier trained on a corpus of malicious and benign PDF files to produce an accurate model to distinguish malicious PDF files from normal documents actually learned incidental associations, such as “a PDF file with pages is probably benign.” This is a pattern in the training data, since most of the malicious PDFs do not bother to include any content pages, just the malicious payload. But, it&#8217;s not a useful property for distinguishing malware, since a malware author can </span><a href="https://evademl.org/docs/evademl.pdf" target="_blank" rel="noopener noreferrer"><span style="font-weight: 400;">easily add pages to a PDF file</span></a><span style="font-weight: 400;"> without disrupting its malicious behavior.</span></p>
<h2>Adversarial Examples</h2>
<p><span style="font-weight: 400;">AI systems learn about the data they are trained on, and learning algorithms are designed to generalize from that data, but the resulting models can be fragile and unpredictable.</span></p>
<blockquote class="tweet"><p><span style="font-weight: 400;">Organizations deploying AI systems need to carefully consider how those systems can fail and limit the trust placed in them.</span></p></blockquote>
<p><span style="font-weight: 400;">Researchers have developed methods that find tiny perturbations, such as modifying just one or two pixels in an image or changing colors by an amount that is imperceptible to humans, that are enough to change the output prediction. The resulting inputs are known as adversarial examples. Some methods even enable construction of physical objects that confuse classifiers — for example, color patterns can be printed on glasses that lead face-recognition systems to </span><a href="https://www.cs.cmu.edu/~sbhagava/papers/face-rec-ccs16.pdf" target="_blank" rel="noopener noreferrer"><span style="font-weight: 400;">misidentify people as targeted victims</span></a><span style="font-weight: 400;">.</span></p>
<h2>Reflecting and Amplifying Bias</h2>
<p><span style="font-weight: 400;">The behavior of AI systems depends on the data they are trained on, and models trained on biased data will reflect those biases. Many well-minded efforts have sought to use algorithms running on unbiased machines to replace the </span><a href="https://www.brinknews.com/algorithms-are-fraught-with-bias-is-there-a-fix/" target="_blank" rel="noopener noreferrer"><span style="font-weight: 400;">inherently biased humans</span></a><span style="font-weight: 400;"> who make critical decisions impacting humans such as granting loans, whether a defendant should be released pending trial and which job candidates to interview.</span></p>
<p><span style="font-weight: 400;">Unfortunately, there is no way to ensure the algorithms themselves are unbiased, and removing humans from these decision processes risks entrenching those biases. One company, for example, used data from its current employees to train a system to scan resumes to identify interview candidates; the system learned to be biased against women, since </span><a href="https://www.reuters.com/article/us-amazon-com-jobs-automation-insight/amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK08G" target="_blank" rel="noopener noreferrer"><span style="font-weight: 400;">the resumes it was trained on</span></a><span style="font-weight: 400;"> were predominantly from male applicants.</span></p>
<h2>Revealing Too Much</h2>
<p><span style="font-weight: 400;">AI systems trained on private data such has health records or emails learn to make predictions based on patterns in that data. Unfortunately, they may also reveal sensitive information about that training data.</span></p>
<p><span style="font-weight: 400;">One risk is membership inference, which is an attack where an adversary with access to a model trained on private data can learn from the model’s outputs whether or not an individual’s record was part of the training data. This poses a privacy risk, especially if the model is trained on medical records for patients with a particular disease. Models can also memorize specific information in their training data. A language model trained on an email corpus </span><a href="https://arxiv.org/abs/1802.08232" target="_blank" rel="noopener noreferrer"><span style="font-weight: 400;">might reveal social security numbers</span></a><span style="font-weight: 400;"> contained in those training emails.</span></p>
<h2>What Can We Do?</h2>
<p><span style="font-weight: 400;">Many researchers are actively working on understanding and mitigating these problems — but although methods exist to mitigate some specific problems, we are a long way from comprehensive solutions. </span></p>
<p><span style="font-weight: 400;">Organizations deploying AI systems need to carefully consider how those systems can fail and limit the trust placed in them. It is also important to consider whether simpler and more understandable methods can provide equally good solutions before jumping into complex AI techniques like deep learning. In one high-profile example, where considering an AI solution should have raised some red flags, a model for predicting recidivism risk was </span><a href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing" target="_blank" rel="noopener noreferrer"><span style="font-weight: 400;">suspected of racial bias</span></a><span style="font-weight: 400;"> in its predictions. A simple model using only three rules based on age, sex and number of prior offenses was found to make </span><a href="https://arxiv.org/abs/1811.10154" target="_blank" rel="noopener noreferrer"><span style="font-weight: 400;">equally good predictions</span></a><span style="font-weight: 400;">.</span></p>
<p><span style="font-weight: 400;">AI technologies show great promise and have demonstrated capacity to improve medical diagnosis, automate business processes and free humans from tedious and unrewarding tasks. But decisions about using AI need to also pay attention to the risks and potential pitfalls in using complex, fragile and poorly understood technologies.</span></p>

      </div>
<hr class="post-separator"></hr>

    
    <footer>
      <nav>
	<a href="/post/" class="button hollow primary">All Posts</a>
      </nav>
    </footer>

</div>
</div>


    </main>
    
    
    <footer class="whatisthis">
  <hr />
  <div class="row">
    <div class="column small-6 medium-2">
      <figure class="full-figure">
	<a href="//jeffersonswheel.org"><img src="/images/jwlogo-tsmall.png" width="200" height="122" alt="Jefferson's Wheel"></a>
	
      </figure>
    </div>
    <div class="column small-12 medium-4">
      <a href="//jeffersonswheel.org"><b>Security Research Group</b></a><br>
      <a href="//www.cs.virginia.edu/">University of Virginia</a><br>
      <a href="mailto:evans@virginia.edu"><em>evans@virginia.edu</em></a>
    </div>
    <div class="column small-14 medium-5">
      <font size="-1">
      Subscribe to
	the <a href="/index.xml"><i class="fa fa-rss-square"></i>&nbsp;RSS feed</a>.
      <a id="searchsite">
	<form method="get" action="https://duckduckgo.com/">
	  <label for="search-field" class="show-for-sr">Search with DuckDuckGo</label>
	  <input type="search" name="q" maxlength="255" placeholder="Search with DuckDuckGo" id="search-field">
	  <input type="hidden" name="sites" value="//jeffersonswheel.org/"/>
	  <input type="hidden" name="k7" value="#faf8f8"/>
	  <input type="hidden" name="kj" value="#b33"/>
	  <input type="hidden" name="ky" value="#fafafa"/>
	  <input type="hidden" name="kx" value="b"/>
	  <input type="hidden" name="ko" value="-1"/>
	  <input type="hidden" name="k1" value="-1"/>
	  <input type="submit" value="DuckDuckGo Search" style="visibility: hidden;" />
	</form>
      </a>
</font>
    </div>
  </div>
</footer>

    
    
    <div class="endofpage">
    </div>

    <script src="/js/jquery.js"></script>
    <script src="/js/what-input.js"></script>
    <script src="/js/foundation.min.js"></script>
    <script src="/js/finite.js"></script>

    
    <script src="/js/highlight.pack.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>

    
    
    
  </body>
</html>
