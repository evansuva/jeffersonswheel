<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>Jefferson&#039;s Wheel &#187; Research</title>
	<atom:link href="http://www.jeffersonswheel.org/category/research/feed" rel="self" type="application/rss+xml" />
	<link>https://www.jeffersonswheel.org</link>
	<description>Security Research at the University of Virginia</description>
	<lastBuildDate>Sun, 14 Oct 2018 03:12:33 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>hourly</sy:updatePeriod>
	<sy:updateFrequency>1</sy:updateFrequency>
	<generator>http://wordpress.org/?v=3.5.1</generator>
		<item>
		<title>Artificial intelligence: the new ghost in the machine</title>
		<link>https://www.jeffersonswheel.org/2018/artificial-intelligence-the-new-ghost-in-the-machine</link>
		<comments>https://www.jeffersonswheel.org/2018/artificial-intelligence-the-new-ghost-in-the-machine#comments</comments>
		<pubDate>Sun, 14 Oct 2018 03:11:46 +0000</pubDate>
		<dc:creator>David Evans</dc:creator>
				<category><![CDATA[Adversarial Machine Learning]]></category>
		<category><![CDATA[Research]]></category>
		<category><![CDATA[Talks]]></category>

		<guid isPermaLink="false">https://www.jeffersonswheel.org/?p=900</guid>
		<description><![CDATA[Engineering and Technology Magazine (a publication of the British Institution of Engineering and Technology) has an article that highlights adversarial machine learning research: Artificial intelligence: the new ghost in the machine, 10 October 2018, by Chris Edwards. Although researchers such as David Evans of the University of Virginia see a full explanation being a little [...]]]></description>
				<content:encoded><![CDATA[<p><em>Engineering and Technology</em> Magazine (a publication of the British <a href="https://www.theiet.org">Institution of Engineering and Technology</a>) has an article that highlights adversarial machine learning research: <a href="https://eandt.theiet.org/content/articles/2018/10/artificial-intelligence-the-new-ghost-in-the-machine/"><em>Artificial intelligence: the new ghost in the machine</em></a>, 10 October 2018, by Chris Edwards.</p>
<p><center><br />
<img src="https://eandt.theiet.org/media/7065/feature_501008906335871317828.jpg?anchor=center&#038;mode=crop&#038;width=400&#038;height=267&#038;rnd=131836400900000000"><br />
</center></p>
<blockquote><p>
Although researchers such as David Evans of the University of Virginia see a full explanation being a little way off in the future, the massive number of parameters encoded by DNNs and the avoidance of overtraining due to SGD may have an answer to why the networks can hallucinate images and, as a result, see things that are not there and ignore those that are.<br />
&#8230;<br />
He points to work by PhD student Mainuddin Jonas that shows how adversarial examples can push the output away from what we would see as the correct answer. &#8220;It could be just one layer [that makes the mistake]. But from our experience it seems more gradual. It seems many of the layers are being exploited, each one just a little bit. The biggest differences may not be apparent until the very last layer.&#8221;<br />
&#8230;<br />
Researchers such as Evans predict a lengthy arms race in attacks and countermeasures that may on the way reveal a lot more about the nature of machine learning and its relationship with reality.
</p></blockquote>
]]></content:encoded>
			<wfw:commentRss>https://www.jeffersonswheel.org/2018/artificial-intelligence-the-new-ghost-in-the-machine/feed</wfw:commentRss>
		<slash:comments>0</slash:comments>
		</item>
		<item>
		<title>Violations of Children&#8217;s Privacy Laws</title>
		<link>https://www.jeffersonswheel.org/2018/violations-of-childrens-privacy-laws</link>
		<comments>https://www.jeffersonswheel.org/2018/violations-of-childrens-privacy-laws#comments</comments>
		<pubDate>Sun, 16 Sep 2018 17:43:48 +0000</pubDate>
		<dc:creator>David Evans</dc:creator>
				<category><![CDATA[Alumni]]></category>
		<category><![CDATA[News]]></category>
		<category><![CDATA[Privacy]]></category>
		<category><![CDATA[Research]]></category>

		<guid isPermaLink="false">https://www.jeffersonswheel.org/?p=889</guid>
		<description><![CDATA[The New York Times has an article, How Game Apps That Captivate Kids Have Been Collecting Their Data about a lawsuit the state of New Mexico is bringing against app markets (including Google) that allow apps presented as being for children in the Play store to violate COPPA rules and mislead users into tracking children. [...]]]></description>
				<content:encoded><![CDATA[<p>The New York Times has an article, <a href="https://www.nytimes.com/interactive/2018/09/12/technology/kids-apps-data-privacy-google-twitter.html"><em>How Game Apps That Captivate Kids Have Been Collecting Their Data</em></a> about a lawsuit the state of New Mexico is bringing against app markets (including Google) that allow apps presented as being for children in the Play store to violate COPPA rules and mislead users into tracking children. The lawsuit stems from a study led by Serge Egleman’s group at UC Berkeley that analyzed COPPA violations in children’s apps. Serge was an undergraduate student here (back in the early 2000s) &#8211; one of the things he did as a undergraduate was successfully sue a spammer.</p>
<p>The original paper about the study: <a href="https://blues.cs.berkeley.edu/wp-content/uploads/2018/04/popets-2018-0021.pdf">“Won’t Somebody Think of the Children?” Examining COPPA Compliance at Scale</a>, Irwin Reyes, Primal Wijesekera, Joel Reardon, Amit Elazari Bar On, Abbas Razaghpanah, Narseo Vallina-Rodriguez, and Serge Egelman. Proceedings on Privacy Enhancing Technologies (PETS) 2018.</p>
<p><center><br />
<img src="https://static01.nyt.com/images/2018/09/13/autossell/13Kidapps2/13Kidapps2-superJumbo.jpg" width=600><br />
Serge Egelman, a researcher with the International Computer Science Institute and the University of California, Berkeley, helped lead the study of nearly 6,000 children’s Android apps<br />
</center></p>
]]></content:encoded>
			<wfw:commentRss>https://www.jeffersonswheel.org/2018/violations-of-childrens-privacy-laws/feed</wfw:commentRss>
		<slash:comments>0</slash:comments>
		</item>
		<item>
		<title>USENIX Security 2018</title>
		<link>https://www.jeffersonswheel.org/2018/usenix-security-2018</link>
		<comments>https://www.jeffersonswheel.org/2018/usenix-security-2018#comments</comments>
		<pubDate>Sun, 19 Aug 2018 19:20:52 +0000</pubDate>
		<dc:creator>David Evans</dc:creator>
				<category><![CDATA[Conferences]]></category>
		<category><![CDATA[Privacy]]></category>
		<category><![CDATA[Research]]></category>

		<guid isPermaLink="false">https://www.jeffersonswheel.org/?p=892</guid>
		<description><![CDATA[Nathaniel Grevatt (&#8220;GDPR-Compliant Data Processing: Improving Pseudonymization with Multi-Party Computation&#8221;), Matthew Wallace and Parvesh Samayamanthula (&#8220;Deceiving Privacy Policy Classifiers with Adversarial Examples&#8221;), and Guy Verrier (&#8220;How is GDPR Affecting Privacy Policies?&#8221;, joint with Haonan Chen and Yuan Tian) presented posters at USENIX Security Symposium 2018 in Baltimore, Maryland. There were also a surprising number of [...]]]></description>
				<content:encoded><![CDATA[<p>Nathaniel Grevatt (&#8220;GDPR-Compliant Data Processing: Improving Pseudonymization with Multi-Party Computation&#8221;), Matthew Wallace and Parvesh Samayamanthula (&#8220;Deceiving Privacy Policy Classifiers with Adversarial Examples&#8221;), and Guy Verrier (&#8220;How is GDPR Affecting Privacy Policies?&#8221;, joint with Haonan Chen and Yuan Tian) presented posters at <a href="https://www.usenix.org/conference/usenixsecurity18/poster-session">USENIX Security Symposium 2018</a> in Baltimore, Maryland. </p>
<p><center></p>
<table width="650">
<tr>
<td align="center">
<a href="/images/usenix2018/IMG_20180816_190616-2.jpg"><img align="center" src="/images/usenix2018/IMG_20180816_190616.jpg" height=220>
</td>
<td href="/images/usenix2018/IMG_20180816_190626-2.jpg"><img align="center" src="/images/usenix2018/IMG_20180816_190626.jpg" height=220>
</td>
</tr>
<tr>
<td align="center">
<a href="/images/usenix2018/IMG_20180816_192620-2.jpg"><img align="center" src="/images/usenix2018/IMG_20180816_192620.jpg" height=220>
</td>
<td href="/images/usenix2018/IMG_20180816_192646-2.jpg"><img align="center" src="/images/usenix2018/IMG_20180816_192646.jpg" height=220>
</td>
</tr>
</table>
<p>There were also a surprising number of appearances by an unidentified unicorn:<br />
<center></p>
<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">Your poster may have made the cut for the <a href="https://twitter.com/hashtag/usesec18?src=hash&amp;ref_src=twsrc%5Etfw">#usesec18</a> Poster Reception, but has it received the approval of a tiny, adorable unicorn? <a href="https://twitter.com/UVA?ref_src=twsrc%5Etfw">@UVA</a> <a href="https://twitter.com/hashtag/seenatusesec18?src=hash&amp;ref_src=twsrc%5Etfw">#seenatusesec18</a> <a href="https://twitter.com/hashtag/girlswhocode?src=hash&amp;ref_src=twsrc%5Etfw">#girlswhocode</a> <a href="https://twitter.com/hashtag/futurecomputerscientist?src=hash&amp;ref_src=twsrc%5Etfw">#futurecomputerscientist</a> <a href="https://twitter.com/hashtag/dreambig?src=hash&amp;ref_src=twsrc%5Etfw">#dreambig</a> <a href="https://t.co/bZOO6lYLXK">pic.twitter.com/bZOO6lYLXK</a></p>
<p>&mdash; USENIX Security (@USENIXSecurity) <a href="https://twitter.com/USENIXSecurity/status/1030215384505491456?ref_src=twsrc%5Etfw">August 16, 2018</a></p></blockquote>
<p><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script><br />
</center></p>
]]></content:encoded>
			<wfw:commentRss>https://www.jeffersonswheel.org/2018/usenix-security-2018/feed</wfw:commentRss>
		<slash:comments>0</slash:comments>
		</item>
		<item>
		<title>Mutually Assured Destruction and the Impending AI Apocalypse</title>
		<link>https://www.jeffersonswheel.org/2018/mutually-assured-destruction-and-the-impending-ai-apocalypse</link>
		<comments>https://www.jeffersonswheel.org/2018/mutually-assured-destruction-and-the-impending-ai-apocalypse#comments</comments>
		<pubDate>Tue, 14 Aug 2018 03:25:27 +0000</pubDate>
		<dc:creator>David Evans</dc:creator>
				<category><![CDATA[Adversarial Machine Learning]]></category>
		<category><![CDATA[Conferences]]></category>
		<category><![CDATA[Research]]></category>
		<category><![CDATA[Security]]></category>
		<category><![CDATA[Talks]]></category>

		<guid isPermaLink="false">https://www.jeffersonswheel.org/?p=883</guid>
		<description><![CDATA[I gave a keynote talk at USENIX Workshop of Offensive Technologies, Baltimore, Maryland, 13 August 2018. The title and abstract are what I provided for the WOOT program, but unfortunately (or maybe fortunately for humanity!) I wasn&#8217;t able to actually figure out a talk to match the title and abstract I provided. The history of [...]]]></description>
				<content:encoded><![CDATA[<p>I gave a keynote talk at <a href="https://www.usenix.org/conference/woot18/workshop-program">USENIX Workshop of Offensive Technologies</a>, Baltimore, Maryland, 13 August 2018. </p>
<p>The title and abstract are what I provided for the WOOT program, but unfortunately (or maybe fortunately for humanity!) I wasn&#8217;t able to actually figure out a talk to match the title and abstract I provided.</p>
<blockquote><p>
The history of security includes a long series of arms races, where a new technology emerges and is subsequently developed and exploited by both defenders and attackers. Over the past few years, &#8220;Artificial Intelligence&#8221; has re-emerged as a potentially transformative technology, and deep learning in particular has produced a barrage of amazing results. We are in the very early stages of understanding the potential of this technology in security, but more worryingly, seeing how it may be exploited by malicious individuals and powerful organizations. In this talk, I&#8217;ll look at what lessons might be learned from previous security arms races, consider how asymmetries in AI may be exploited by attackers and defenders, touch on some recent work in adversarial machine learning, and hopefully help progress-loving Luddites figure out how to survive in a world overrun by AI doppelgängers, GAN gangs, and gibbon-impersonating pandas.
</p></blockquote>
<p><script async class="speakerdeck-embed" data-id="5f72d8151bae4c5a9bb54ab33372f125" data-ratio="1.77777777777778" src="//speakerdeck.com/assets/embed.js" width="650"></script></p>
]]></content:encoded>
			<wfw:commentRss>https://www.jeffersonswheel.org/2018/mutually-assured-destruction-and-the-impending-ai-apocalypse/feed</wfw:commentRss>
		<slash:comments>0</slash:comments>
		</item>
		<item>
		<title>Dependable and Secure Machine Learning</title>
		<link>https://www.jeffersonswheel.org/2018/dependable-and-secure-machine-learning</link>
		<comments>https://www.jeffersonswheel.org/2018/dependable-and-secure-machine-learning#comments</comments>
		<pubDate>Sat, 07 Jul 2018 22:30:07 +0000</pubDate>
		<dc:creator>David Evans</dc:creator>
				<category><![CDATA[Conferences]]></category>
		<category><![CDATA[Machine Learning]]></category>
		<category><![CDATA[Research]]></category>

		<guid isPermaLink="false">https://www.jeffersonswheel.org/?p=880</guid>
		<description><![CDATA[I co-organized, with Homa Alemzadeh and Karthik Pattabiraman, a workshop on trustworthy machine learning attached to DSN 2018, in Luxembourg: DSML: Dependable and Secure Machine Learning.]]></description>
				<content:encoded><![CDATA[<p>I co-organized, with <a href="http://faculty.virginia.edu/alemzadeh/">Homa Alemzadeh</a> and <a href="http://blogs.ubc.ca/karthik/">Karthik Pattabiraman</a>, a workshop on trustworthy machine learning attached to DSN 2018, in Luxembourg: <a href="https://dependablesecureml.github.io/">DSML: Dependable and Secure Machine Learning</a>.</p>
]]></content:encoded>
			<wfw:commentRss>https://www.jeffersonswheel.org/2018/dependable-and-secure-machine-learning/feed</wfw:commentRss>
		<slash:comments>0</slash:comments>
		</item>
		<item>
		<title>SRG at IEEE S&amp;P 2018</title>
		<link>https://www.jeffersonswheel.org/2018/srg-at-ieee-sp-2018</link>
		<comments>https://www.jeffersonswheel.org/2018/srg-at-ieee-sp-2018#comments</comments>
		<pubDate>Wed, 30 May 2018 01:47:52 +0000</pubDate>
		<dc:creator>David Evans</dc:creator>
				<category><![CDATA[Adversarial Machine Learning]]></category>
		<category><![CDATA[Conferences]]></category>
		<category><![CDATA[Pictures]]></category>
		<category><![CDATA[Research]]></category>

		<guid isPermaLink="false">https://www.jeffersonswheel.org/?p=849</guid>
		<description><![CDATA[Group Dinner Including our newest faculty member, Yongwhi Kwon, joining UVA in Fall 2018! Yuan Tian, Fnu Suya, Mainuddin Jonas, Yongwhi Kwon, David Evans, Weihang Wang, Aihua&#160;Chen,&#160;Weilin&#160;Xu Poster Session Fnu Suya (with Yuan Tian and David Evans), Adversaries Don’t Care About Averages: Batch Attacks on Black-Box Classifiers [PDF] Mainuddin Jonas (with David Evans), Enhancing Adversarial [...]]]></description>
				<content:encoded><![CDATA[<p><b>Group Dinner</b></p>
<p>
<center><br />
Including our newest faculty member, <a href="https://www.cs.purdue.edu/homes/kwon58/#summary">Yongwhi Kwon</a>, joining UVA in Fall 2018!<br />
<a href="/images/srg2018/ORG_DSC07202.jpg"><img src="/images/srg2018/ORG_DSC07202.jpg" width="680"></a><br />
<small>Yuan Tian, Fnu Suya, Mainuddin Jonas, Yongwhi Kwon, David Evans, Weihang Wang, Aihua&nbsp;Chen,&nbsp;Weilin&nbsp;Xu</small><br />
</center>
</p>
<p>
<b>Poster Session</b></p>
<table width="100%">
<tr valign="top">
<td width="50%" align="center">
<a href="/images/srg2018/IMG_20180521_193906.jpg"><img src="/images/srg2018/IMG_20180521_193906-3.jpg" height="360"></a><br />
Fnu Suya (with Yuan Tian and David Evans), <em>Adversaries Don’t Care About Averages: Batch Attacks on Black-Box Classifiers</em> <a href="https://www.ieee-security.org/TC/SP2018/poster-abstracts/oakland2018-paper37-poster-abstract.pdf">[PDF]</a>
</td>
<td width="50%" align="center">
<a href="/images/srg2018/IMG_20180521_193914.jpg"><img src="/images/srg2018/IMG_20180521_193914-2.jpg" height="360"></a><br />
Mainuddin Jonas (with David Evans), <em>Enhancing Adversarial Example Defenses Using Internal Layers</em> <a href="https://www.ieee-security.org/TC/SP2018/poster-abstracts/oakland2018-paper29-poster-abstract.pdf">[PDF]</a>
</td>
</tr>
<tr valign="top">
<td width="50%" align="center">
<a href="/images/srg2018/IMG_20180522_153017.jpg"><img src="/images/srg2018/IMG_20180522_153017-2.jpg" height="300"></a>
</td>
<td width="50%" align="center">
<a href="/images/srg2018/IMG_20180522_153109.jpg"><img src="/images/srg2018/IMG_20180522_153109-2.jpg" height="300"></a>
</td>
</tr>
</table>
]]></content:encoded>
			<wfw:commentRss>https://www.jeffersonswheel.org/2018/srg-at-ieee-sp-2018/feed</wfw:commentRss>
		<slash:comments>0</slash:comments>
		</item>
		<item>
		<title>Huawei STW: Lessons from the Last 3000 Years of Adversarial Examples</title>
		<link>https://www.jeffersonswheel.org/2018/huawei-stw-lessons-from-the-last-3000-years-of-adversarial-examples</link>
		<comments>https://www.jeffersonswheel.org/2018/huawei-stw-lessons-from-the-last-3000-years-of-adversarial-examples#comments</comments>
		<pubDate>Thu, 24 May 2018 02:31:43 +0000</pubDate>
		<dc:creator>David Evans</dc:creator>
				<category><![CDATA[Adversarial Machine Learning]]></category>
		<category><![CDATA[Research]]></category>
		<category><![CDATA[Talks]]></category>

		<guid isPermaLink="false">https://www.jeffersonswheel.org/?p=868</guid>
		<description><![CDATA[I spoke on Lessons from the Last 3000 Years of Adversarial Examples at Huawei&#8217;s Strategy and Technology Workshop in Shenzhen, China, 15 May 2018. We also got to tour Huawei&#8217;s new research and development campus, under construction about 40 minutes from Shenzhen. It is pretty close to Disneyland, with its own railroad and villages themed [...]]]></description>
				<content:encoded><![CDATA[<p>I spoke on <em>Lessons from the Last 3000 Years of Adversarial Examples</em> at Huawei&#8217;s Strategy and Technology Workshop in Shenzhen, China, 15 May 2018.  </p>
<p>
<script async class="speakerdeck-embed" data-id="3de1c0f163b44ab18e4928c58eea706e" data-ratio="1.77777777777778" src="//speakerdeck.com/assets/embed.js"></script>
</p>
<p>
We also got to tour Huawei&#8217;s new research and development campus, under construction about 40 minutes from Shenzhen. It is pretty close to Disneyland, with its own railroad and villages themed after different European cities (Paris, Bologna, etc.).<br />
<center><br />
<a href="/images/029.jpg"><img src="/images/029.jpg" width="650"></a><br />
Huawei&#8217;s New Research and Development Campus [<a href="https://photos.app.goo.gl/YqGfaC6fqNAsywzd2">More Pictures</a>]<br />
</center></p>
<p>
Unfortunately, pictures were not allowed on our tour of the production line. Not so surprising that nearly all of the work was done by machines, but was surprising to me how much of the human work left is completely robotic. The human workers (called &#8220;operators&#8221;) are mostly scanning QR codes on parts, and following the directions that light up with they do, or scanning bins and following directions on a screen to collect parts from bins and scanning them when they are put into the bin. This is the kind of system that leads to remarkably high production quality. The parts are mostly delivered on tapes that are fed into the machines, and many machines along the line are primarily for testing. There is a &#8220;bottleneck&#8221; marker that is placed on any points that are holding up the production line.
</p>
<p>
The public (at least to the factory) &#8220;grapey board&#8221; keeps track of the happiness of the workers &mdash; each operator puts up a smiley (or frowny) face on the board to show their mood for the day, monitored carefully by the managers.  There is a batch of grapes to show performance for the month. If an operator does something good, a grape is colored green; if they do something bad, a grape is colored black. There was quite a bit of discussion among the people on the tour (mostly US and European-based professors) if such a management approach would be a good idea for our research groups&#8230; (or for department chairs for their faculty!)
</p>
<p><center><br />
<a href="/images/048.jpg"><img src="/images/048.jpg" width="650"></a><br />
In front of Huawei&#8217;s &#8220;White House&#8221;, with Battista Biggio [<a href="https://photos.app.goo.gl/YqGfaC6fqNAsywzd2">More Pictures</a>]<br />
</center></p>
]]></content:encoded>
			<wfw:commentRss>https://www.jeffersonswheel.org/2018/huawei-stw-lessons-from-the-last-3000-years-of-adversarial-examples/feed</wfw:commentRss>
		<slash:comments>0</slash:comments>
		</item>
		<item>
		<title>Feature Squeezing at NDSS</title>
		<link>https://www.jeffersonswheel.org/2018/feature-squeezing-at-ndss</link>
		<comments>https://www.jeffersonswheel.org/2018/feature-squeezing-at-ndss#comments</comments>
		<pubDate>Sun, 25 Feb 2018 23:00:52 +0000</pubDate>
		<dc:creator>David Evans</dc:creator>
				<category><![CDATA[Adversarial Machine Learning]]></category>
		<category><![CDATA[Machine Learning]]></category>
		<category><![CDATA[Research]]></category>
		<category><![CDATA[Security]]></category>
		<category><![CDATA[Talks]]></category>

		<guid isPermaLink="false">https://www.jeffersonswheel.org/?p=843</guid>
		<description><![CDATA[Weilin Xu presented Feature Squeezing: Detecting Adversarial Examples in Deep Neural Networks at the Network and Distributed System Security Symposium 2018. San Diego, CA. 21 February 2018. Paper: Weilin Xu, David Evans, Yanjun Qi. Feature Squeezing: Detecting Adversarial Examples in Deep Neural Networks. NDSS 2018. [PDF] Project Site]]></description>
				<content:encoded><![CDATA[<p>Weilin Xu presented <em>Feature Squeezing: Detecting Adversarial Examples in Deep Neural Networks</em> at the <a href="http://www.ndss-symposium.org/ndss2018/">Network and Distributed System Security Symposium 2018</a>. San Diego, CA. 21 February 2018.<br />
<center><br />
<script async class="speakerdeck-embed" data-id="cdfcf454436240e4ab1a6c4d594e5c7a" data-ratio="1.77777777777778" src="//speakerdeck.com/assets/embed.js"></script><br />
</center></p>
<p>Paper: Weilin Xu, David Evans, Yanjun Qi. <em>Feature Squeezing: Detecting Adversarial Examples in Deep Neural Networks</em>. NDSS 2018. [<a href="https://evademl.org/docs/featuresqueezing.pdf">PDF</a>]</p>
<p><a href="https://evadeML.org/squeezing">Project Site</a></p>
]]></content:encoded>
			<wfw:commentRss>https://www.jeffersonswheel.org/2018/feature-squeezing-at-ndss/feed</wfw:commentRss>
		<slash:comments>0</slash:comments>
		</item>
		<item>
		<title>Highlights from CCS 2017</title>
		<link>https://www.jeffersonswheel.org/2017/highlights-from-ccs-2017</link>
		<comments>https://www.jeffersonswheel.org/2017/highlights-from-ccs-2017#comments</comments>
		<pubDate>Sat, 18 Nov 2017 23:47:40 +0000</pubDate>
		<dc:creator>David Evans</dc:creator>
				<category><![CDATA[Alumni]]></category>
		<category><![CDATA[Conferences]]></category>
		<category><![CDATA[Privacy]]></category>
		<category><![CDATA[Research]]></category>
		<category><![CDATA[Security]]></category>

		<guid isPermaLink="false">https://www.jeffersonswheel.org/?p=824</guid>
		<description><![CDATA[The 24th ACM Conference on Computer and Communications Security was held in Dallas, 30 October &#8211; 3 November. Being Program Committee co-chair for a conference like this is a full-year commitment, and the work continues throughout much of the year preceding the conference. The conference has over 1000 registered attendees, a record for any academic [...]]]></description>
				<content:encoded><![CDATA[<p>The <a href="https://ccs2017.sigsac.org">24<sup>th</sup> <em>ACM Conference on Computer and Communications Security</em></a> was held in Dallas, 30 October &ndash; 3 November. Being Program Committee co-chair for a conference like this is a full-year commitment, and the work continues throughout much of the year preceding the conference. The conference has over 1000 registered attendees, a record for any academic security research conference.</p>
<p>
Here are a few highlights from the conference week.
</p>
<p>
<center><br />
<script async class="speakerdeck-embed" data-id="a5ca2b52d1a046d59b1bcc6f7e4ab6b9" data-ratio="1.77777777777778" src="//speakerdeck.com/assets/embed.js"></script><br />
<b>PC Chairs&#8217; Welcome</b> (opening session)<br />
</center>
</p>
<p>
<center><br />
<a href="//www.cs.virginia.edu/evans/pictures/ccs2017/ccsopening.jpg"><img src="//www.cs.virginia.edu/evans/pictures/ccs2017/ccsopening-small.jpg" width="640" height="427"><br />
Giving the PC Chairs&#8217; Welcome Talk<br />
</center>
</p>
<p>
<center><br />
<a href="//www.cs.virginia.edu/evans/pictures/ccs2017/ccsaudience.jpg"><img src="//www.cs.virginia.edu/evans/pictures/ccs2017/ccsaudience-small.jpg" width="640" height="427"><br />
Audience at Opening Session<br />
</center>
</p>
<p>
<center><br />
<a href="https://acmccs.github.io/images/finalists.jpg"><img src="https://acmccs.github.io/images/finalists.jpg" width="640"</a></br><b>ACM CCS 2017 Paper Awards Finalists</b><br />
</center>
</p>
<p>
<center><br />
<a href="//www.cs.virginia.edu/evans/pictures/ccs2017/ccsbanquet.jpg"><img src="//www.cs.virginia.edu/evans/pictures/ccs2017/ccsbanquet-small.jpg" width="640"></a><br />
<b>CCS 2017 Awards Banquet</b><br />
</center>
</p>
<p>
<center><br />
<a href="//www.cs.virginia.edu/evans/pictures/ccs2017/doerner-award.jpg"><img src="//www.cs.virginia.edu/evans/pictures/ccs2017/doerneraward-small.jpg"</img></a><br />
</center><br />
At the <a href="https://ccs2017.sigsac.org/awards.html">Award&#8217;s Banquet</a>, I got to award a Best Paper award to SRG alum Jack Doerner (I was, of course, recused by conflict from being involved in any decisions on his paper).<br />
</center>
</p>
<p>
<center><br />
<a href="//www.cs.virginia.edu/evans/pictures/ccs2017/uvalunch.jpg"><img src="//www.cs.virginia.edu/evans/pictures/ccs2017/uvalunch-small.jpg" width="640"></a><br />
</center><br />
<b>UVA Lunch</b> (around the table starting at front left): Suman Jana (honorary Wahoo by marriage), Darion Cassel (SRG BSCS 2017, now at CMU), Will Hawkins, Jason Hiser, Samee Zahur (SRG PhD 2016, now at Google), Jack Doerner (SRG BACS 2016, now at Northeastern), Joe Calandrino (now at FTC); Back right to front: Ben Kreuter (now at Google), Anh Nguyen-Tuong, Jack Davidson, Yuan Tian, Yuchen Zhou (SRG PhD 2015, now at Palo Alto Networks), David Evans.<br />
</center></p>
]]></content:encoded>
			<wfw:commentRss>https://www.jeffersonswheel.org/2017/highlights-from-ccs-2017/feed</wfw:commentRss>
		<slash:comments>0</slash:comments>
		</item>
		<item>
		<title>First Workshop for Women in Cybersecurity</title>
		<link>https://www.jeffersonswheel.org/2017/first-workshop-for-women-in-cybersecurity</link>
		<comments>https://www.jeffersonswheel.org/2017/first-workshop-for-women-in-cybersecurity#comments</comments>
		<pubDate>Fri, 17 Nov 2017 13:02:43 +0000</pubDate>
		<dc:creator>David Evans</dc:creator>
				<category><![CDATA[Conferences]]></category>
		<category><![CDATA[Research]]></category>
		<category><![CDATA[Security]]></category>

		<guid isPermaLink="false">https://www.jeffersonswheel.org/?p=815</guid>
		<description><![CDATA[I gave a talk at the First ACM Workshop for Women in Cybersecurity (affiliated with ACM CCS 2017) on Truth, Social Justice (and the American Way?): There&#8217;s also a short paper, loosely related to the talk: [PDF]]]></description>
				<content:encoded><![CDATA[<p>I gave a talk at the <a href="https://sites.google.com/a/vt.edu/cyberw2017/home"><em>First ACM Workshop for Women in Cybersecurity</em></a> (affiliated with <a href="https://ccs2017.sigsac.org">ACM CCS 2017</a>) on <a href="http://www.cs.virginia.edu/~evans/pubs/cyberw2017/"><em>Truth, Social Justice (and the American Way?)</em></a>:<br />
<center><br />
<script async class="speakerdeck-embed"
        data-id="b8709f70dbae4b54be9f2e38a66ca605"
        data-ratio="1.77777777777778"
        src="//speakerdeck.com/assets/embed.js"></script><br />
</center><br />
There&#8217;s also a short paper, loosely related to the talk: [<a href="http://www.cs.virginia.edu/~evans/pubs/cyberw2017/cyberw.pdf">PDF</a>]</p>
<p>
<center><br />
<a href="//www.cs.virginia.edu/evans/pictures/cyberw2017/BigG1.jpg"><img src="//www.cs.virginia.edu/evans/pictures/cyberw2017/BigG1.jpg" width=650></a><br />
</center>
</p>
<p>
<center><br />
<a href="//www.cs.virginia.edu/evans/pictures/cyberw2017/IMG-1768.jpg"><img src="//www.cs.virginia.edu/evans/pictures/cyberw2017/IMG-1768.jpg" width=650></a><br />
</center></p>
]]></content:encoded>
			<wfw:commentRss>https://www.jeffersonswheel.org/2017/first-workshop-for-women-in-cybersecurity/feed</wfw:commentRss>
		<slash:comments>0</slash:comments>
		</item>
	</channel>
</rss>
